---
title: "Translated Blogs"
weight: 3
chapter: false
pre: " <b> 3 </b> "
---
###  [Blog 1 - Model Customization, RAG, or Both: A Case Study with Amazon Nova](3.1-Blog1/)
In the rapidly evolving Generative AI landscape, choosing the optimal strategy to improve the accuracy of large language models (LLMs) for domain tools can be a big challenge. This paper conducts a case study using Amazon Nova models to compare the performance of three multivariate approaches: Model Fine-Tuning (Fine-Tuning), Retrieval Augmentation Generation (RAG), and Hybrid. Through real-world experiments on the AWS dataset, the paper provides an in-depth analysis of performance, cost, and technical complexity, helping developers and enterprises make the most informed decisions for their AI applications.
###  [Blog 2 - Migrating CDK Version 1 Applications to CDK Version 2 with Amazon Q Developer](3.2-Blog2/)
With AWS CDK v1 officially retired, developers are faced with an urgent need to upgrade to v2 to ensure security and take advantage of the latest features. This article details how to use Amazon Q Developer – an AI-powered programming assistant – to automate and accelerate this migration. From updating dependencies and modifying imports to debugging and documentation, you will discover how Amazon Q makes infrastructure-as-code (IaC) modernization simple, fast, and less error-prone.
###  [Blog 3 - Melting The Ice \- How Natural Intelligence Simplified a Data Lake Migration to Apache Iceberg](3.3-Blog3/)
Migrating a large-scale, operational Data Lake to a modern tabular format like Apache Iceberg often comes with the risk of system disruption and technical complexity. This article is a success story of Natural Intelligence's zero-downtime migration from Apache Hive to Apache Iceberg. The authors share details of an innovative hybrid migration strategy that uses automated schema and change synchronization (CDC) between the old and new systems. This is a valuable reference on architecture and processes for organizations looking to safely and efficiently modernize their big data platforms.


[
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Minh Tuấn\nSố điện thoại: 0981 500 154\nEmail: tuanlmse184475@fpt.edu.vn\nTrường: Đại học FPT TP.Hồ Chí Minh\nNgành: Trí tuệ nhân tạo\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 09/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Tùy chỉnh mô hình, RAG, hay cả hai: Nghiên cứu điển hình với Amazon Nova by Flora Wang, Anila Joshi, Baishali Chaudhury, Sungmin Hong, Jae Oh Woo, and Rahul Ghosh on 10 APR 2025 in Advanced (300), Amazon Bedrock, Amazon Machine Learning, Amazon Nova, Amazon SageMaker, Generative AI, Technical How-to\nKhi các doanh nghiệp và nhà phát triển ngày càng tìm cách tối ưu hóa các mô hình ngôn ngữ của họ cho các nhiệm vụ cụ thể, quyết định giữa tùy chỉnh mô hình và Retrieval Augmented Generation (RAG) trở nên quan trọng. Trong bài đăng này, chúng tôi tìm cách giải quyết nhu cầu ngày càng tăng này bằng cách đưa ra các hướng dẫn rõ ràng, có thể hành động và các phương pháp hay nhất về thời điểm sử dụng từng phương pháp, giúp bạn đưa ra quyết định sáng suốt phù hợp với các yêu cầu và mục tiêu riêng của mình.\nSự ra đời của các mô hình Amazon Nova thể hiện một bước tiến đáng kể trong lĩnh vực AI, mang đến những cơ hội mới để tối ưu hóa mô hình ngôn ngữ lớn (LLM). Trong bài đăng này, chúng tôi trình bày cách thực hiện tùy chỉnh mô hình và RAG một cách hiệu quả với các mô hình Amazon Nova làm cơ sở. Chúng tôi đã tiến hành nghiên cứu so sánh toàn diện giữa tùy chỉnh mô hình và RAG bằng cách sử dụng các mô hình Amazon Nova mới nhất và chia sẻ những thông tin chi tiết có giá trị này.\nTổng quan về cách tiếp cận và mô hình cơ sở Trong phần này, chúng tôi thảo luận về sự khác biệt giữa phương pháp tinh chỉnh và RAG, trình bày các trường hợp sử dụng phổ biến cho từng cách tiếp cận và cung cấp tổng quan về mô hình cơ sở được sử dụng cho các thử nghiệm.\nLàm sáng tỏ RAG và tùy chỉnh mô hình RAG là một kỹ thuật để nâng cao khả năng của các mô hình được đào tạo trước bằng cách cho phép mô hình truy cập vào các nguồn dữ liệu miền cụ thể bên ngoài. Nó kết hợp hai thành phần: truy xuất kiến thức bên ngoài và tạo phản hồi. Nó cho phép các mô hình ngôn ngữ được đào tạo trước kết hợp động dữ liệu bên ngoài trong quá trình tạo phản hồi, cho phép kết quả đầu ra được cập nhật và chính xác hơn theo ngữ cảnh. Không giống như tinh chỉnh, trong RAG, mô hình không trải qua bất kỳ khóa đào tạo nào và trọng số mô hình không được cập nhật để tìm hiểu kiến thức miền. Mặc dù tinh chỉnh ngầm sử dụng thông tin miền cụ thể bằng cách nhúng kiến thức cần thiết trực tiếp vào mô hình, RAG sử dụng rõ ràng thông tin miền cụ thể thông qua truy xuất bên ngoài.\nTùy chỉnh mô hình đề cập đến việc điều chỉnh mô hình ngôn ngữ được đào tạo trước để phù hợp hơn với các tác vụ, miền hoặc tập dữ liệu cụ thể. Tinh chỉnh là một trong những kỹ thuật như vậy, giúp đưa kiến thức cụ thể về nhiệm vụ hoặc lĩnh vực cụ thể để cải thiện hiệu suất mô hình. Nó điều chỉnh các thông số của mô hình để phù hợp hơn với các sắc thái của nhiệm vụ mục tiêu trong khi sử dụng kiến thức chung của nó.\nCác trường hợp sử dụng phổ biến cho từng cách tiếp cận RAG tối ưu cho các trường hợp sử dụng yêu cầu dữ liệu động hoặc cập nhật thường xuyên (chẳng hạn như Câu hỏi thường gặp về hỗ trợ khách hàng và danh mục thương mại điện tử), thông tin chi tiết về miền cụ thể (chẳng hạn như Hỏi \u0026amp; Đáp pháp lý hoặc y tế), các giải pháp có thể mở rộng cho các ứng dụng rộng (chẳng hạn như nền tảng phần mềm dưới dạng dịch vụ (SaaS)), truy xuất dữ liệu đa phương thức (chẳng hạn như tóm tắt tài liệu) và tuân thủ nghiêm ngặt dữ liệu an toàn hoặc nhạy cảm (chẳng hạn như hệ thống tài chính và quy định).\nNgược lại, tinh chỉnh phát triển mạnh trong các tình huống yêu cầu tùy chỉnh chính xác (chẳng hạn như chatbot được cá nhân hóa hoặc viết sáng tạo), độ chính xác cao cho các tác vụ hẹp (chẳng hạn như tạo mã hoặc tóm tắt chuyên biệt), độ trễ cực thấp (chẳng hạn như tương tác với khách hàng theo thời gian thực), ổn định với bộ dữ liệu tĩnh (chẳng hạn như bảng thuật ngữ dành riêng cho miền) và mở rộng quy mô hiệu quả về chi phí cho các tác vụ khối lượng lớn (chẳng hạn như tự động hóa trung tâm cuộc gọi).\nMặc dù RAG vượt trội về nền tảng thời gian thực trong dữ liệu bên ngoài và tinh chỉnh chuyên về quy trình làm việc tĩnh, có cấu trúc và được cá nhân hóa, nhưng việc lựa chọn giữa chúng thường phụ thuộc vào các yếu tố sắc thái. Bài đăng này cung cấp so sánh toàn diện về RAG và tinh chỉnh, làm rõ điểm mạnh, hạn chế và bối cảnh của chúng mà mỗi cách tiếp cận mang lại hiệu suất tốt nhất.\nGiới thiệu về các mẫu Amazon Nova Amazon Nova là một thế hệ mô hình nền tảng (FM) mới cung cấp thông tin tiên tiến và hiệu suất giá hàng đầu trong ngành. Amazon Nova Pro và Amazon Nova Lite là những mô hình đa phương thức vượt trội về độ chính xác và tốc độ, với Amazon Nova Lite được tối ưu hóa để xử lý nhanh và chi phí thấp. Amazon Nova Micro tập trung vào các tác vụ văn bản có độ trễ cực thấp. Chúng cung cấp khả năng suy luận nhanh, hỗ trợ quy trình làm việc tác nhân với Cơ sở tri thức Amazon Bedrock và RAG, đồng thời cho phép tinh chỉnh dữ liệu văn bản và đa phương thức. Được tối ưu hóa để có hiệu suất hiệu quả về chi phí, chúng được đào tạo trên dữ liệu bằng hơn 200 ngôn ngữ.\nTổng quan về giải pháp Để đánh giá hiệu quả của RAG so với tùy chỉnh mô hình, chúng tôi đã thiết kế một khung thử nghiệm toàn diện bằng cách sử dụng một tập hợp các câu hỏi dành riêng cho AWS. Nghiên cứu của chúng tôi đã sử dụng Amazon Nova Micro và Amazon Nova Lite làm FM cơ bản và kiểm tra hiệu suất của chúng trên các cấu hình khác nhau.\nChúng tôi đã cấu trúc đánh giá của mình như sau:\nMô hình cơ sở:\nAmazon Nova Micro và Amazon Nova Lite đã qua sử dụng\nCâu trả lời được tạo cho các câu hỏi dành riêng cho AWS mà không cần ngữ cảnh bổ sung\nMô hình cơ sở với RAG:\nKết nối các mô hình cơ sở với Cơ sở tri thức Amazon Bedrock\nĐược cung cấp quyền truy cập vào tài liệu và blog có liên quan của AWS\nTùy chỉnh mô hình:\nTinh chỉnh cả hai mô hình Amazon Nova bằng cách sử dụng 1.000 cặp câu hỏi-câu trả lời dành riêng cho AWS được tạo từ cùng một bộ bài viết AWS\nTriển khai các mô hình tùy chỉnh thông qua thông lượng được cung cấp\nTạo câu trả lời cho các câu hỏi dành riêng cho AWS với các mô hình được tinh chỉnh\nTùy chỉnh mô hình và cách tiếp cận kết hợp RAG:\nKết nối các mô hình tinh chỉnh với Cơ sở tri thức Amazon Bedrock\nCung cấp các mô hình tinh chỉnh quyền truy cập vào các bài viết AWS có liên quan tại thời điểm suy luận\nTrong các phần sau, chúng ta sẽ hướng dẫn cách thiết lập phương pháp tiếp cận thứ hai và thứ ba (mô hình cơ sở với RAG và tùy chỉnh mô hình với tinh chỉnh) trong Amazon Bedrock.\nĐiều kiện tiên quyết Để làm theo bài đăng này, bạn cần các điều kiện tiên quyết sau:\nTài khoản AWS và các quyền thích hợp\nVùng lưu trữ Amazon Simple Storage Service (Amazon S3) với hai thư mục: một thư mục chứa dữ liệu đào tạo của bạn và một thư mục cho đầu ra mô hình và chỉ số đào tạo của bạn\nTriển khai RAG với mô hình Amazon Nova cơ bản Trong phần này, chúng ta sẽ hướng dẫn các bước để triển khai RAG với mô hình cơ sở. Để làm như vậy, chúng tôi tạo ra một cơ sở tri thức. Hoàn thành các bước sau:\nTrên bảng điều khiển Amazon Bedrock, chọn Cơ sở kiến thức trong ngăn điều hướng.\nTrong Cơ sở kiến thức, chọn Tạo.\nTrên trang Đặt cấu hình nguồn dữ liệu, hãy cung cấp thông tin sau:\nChỉ định vị trí Amazon S3 của tài liệu.\nChỉ định chiến lược phân đoạn.\nChọn Tiếp theo.\nTrên trang Chọn mô hình nhúng và đặt cấu hình kho vectơ, hãy cung cấp thông tin sau:\nTrong phần Mô hình nhúng, chọn mô hình nhúng được sử dụng để nhúng các khối.\nTrong phần Cơ sở dữ liệu vectơ, hãy tạo một kho lưu trữ vectơ mới hoặc sử dụng kho lưu trữ vectơ hiện có, nơi các phần nhúng sẽ được lưu trữ để truy xuất.\nChọn Tiếp theo.\nTrên trang Xem lại và tạo, xem lại cài đặt và chọn Tạo cơ sở kiến thức. Tinh chỉnh mô hình Amazon Nova bằng API Amazon Bedrock Trong phần này, chúng tôi cung cấp hướng dẫn chi tiết về cách tinh chỉnh và lưu trữ các mô hình Amazon Nova tùy chỉnh bằng Amazon Bedrock. Sơ đồ sau đây minh họa kiến trúc giải pháp.\nTạo công việc tinh chỉnh Tinh chỉnh các mô hình Amazon Nova thông qua API Amazon Bedrock là một quy trình được sắp xếp hợp lý:\nTrên bảng điều khiển Amazon Bedrock, chọn us-east-1 làm Khu vực AWS của bạn.Tại thời điểm viết bài, tinh chỉnh mô hình Amazon Nova chỉ có sẵn ở us-east-1.\nChọn Mô hình tùy chỉnh trong Mô hình nền tảng trong ngăn điều hướng.\nTrong Phương pháp tùy chỉnh, chọn Tạo công việc tinh chỉnh.\nĐối với Mô hình nguồn, chọn Chọn mô hình.\nChọn Amazon làm nhà cung cấp và mô hình Amazon Nova mà bạn chọn.\nChọn Áp dụng.\nĐối với Tên kiểu máy được tinh chỉnh, hãy nhập tên duy nhất cho kiểu máy được tinh chỉnh.\nĐối với Tên công việc, nhập tên cho công việc tinh chỉnh.\nTrong Dữ liệu đầu vào, nhập vị trí của vùng lưu trữ S3 nguồn (dữ liệu đào tạo) và vùng lưu trữ S3 đích (đầu ra mô hình và chỉ số đào tạo) và tùy chọn vị trí của tập dữ liệu xác thực của bạn.\nĐịnh cấu hình siêu tham số Đối với các mô hình Amazon Nova, bạn có thể tùy chỉnh các siêu tham số sau:\nThông số Phạm vi/Ràng buộc Kỷ nguyên 1–5 Kích thước lô Cố định ở mức 1 Tốc độ học tập 0.000001–0.0001 Các bước khởi động tốc độ học tập 0–100 Chuẩn bị tập dữ liệu để tương thích với các mô hình Amazon Nova Tương tự như các LLM khác, Amazon Nova yêu cầu các cặp hoàn thành lời nhắc, còn được gọi là cặp câu hỏi và câu trả lời (Q\u0026amp;A), để tinh chỉnh có giám sát (SFT). Tập dữ liệu này phải chứa các kết quả lý tưởng mà bạn muốn mô hình ngôn ngữ tạo ra cho các tác vụ hoặc lời nhắc cụ thể. Tham khảo Hướng dẫn chuẩn bị dữ liệu của bạn cho Amazon Nova về các phương pháp thực hành tốt nhất và định dạng ví dụ khi chuẩn bị bộ dữ liệu để tinh chỉnh các mô hình Amazon Nova.\nKiểm tra tinh chỉnh tình trạng công việc và hiện vật đào tạo\nSau khi bạn tạo công việc tinh chỉnh, hãy chọn Mô hình tùy chỉnh trong Mô hình nền tảng trong ngăn điều hướng. Bạn sẽ tìm thấy công việc tinh chỉnh hiện tại được liệt kê trong Công việc. Bạn có thể sử dụng trang này để theo dõi trạng thái công việc tinh chỉnh của mình.\nKhi trạng thái công việc tinh chỉnh của bạn thay đổi thành Hoàn thành, bạn có thể chọn tên công việc và điều hướng đến trang Tổng quan về công việc đào tạo. Bạn sẽ tìm thấy các thông tin sau:\nThông số kỹ thuật công việc đào tạo\nVị trí Amazon S3 cho dữ liệu đầu vào được sử dụng để tinh chỉnh\nSiêu tham số được sử dụng trong quá trình tinh chỉnh\nVị trí Amazon S3 cho đầu ra đào tạo\nLưu trữ mô hình tinh chỉnh với thông lượng được cung cấp Sau khi công việc tinh chỉnh hoàn tất thành công, bạn có thể truy cập mô hình tùy chỉnh của mình thông qua các bước sau:\nTrên bảng điều khiển Amazon Bedrock, chọn Mô hình tùy chỉnh trong Mô hình nền tảng trong ngăn điều hướng.\nTrong Mô hình, chọn mô hình tùy chỉnh của bạn.\nTrang chi tiết kiểu máy hiển thị các thông tin sau:\nChi tiết mô hình được tinh chỉnh\nVị trí Amazon S3 cho dữ liệu đầu vào được sử dụng để tinh chỉnh\nSiêu tham số được sử dụng trong quá trình tinh chỉnh\nVị trí Amazon S3 cho đầu ra đào tạo\nĐể cung cấp mô hình tinh chỉnh của bạn để suy luận, hãy chọn Mua thông lượng được cung cấp.\nChọn thời hạn cam kết (không cam kết, 1 tháng hoặc 6 tháng) và xem lại chi phí liên quan để lưu trữ các mô hình được tinh chỉnh.\nSau khi mô hình tùy chỉnh được lưu trữ thông qua thông lượng được cung cấp, ID mô hình sẽ được gán và có thể được sử dụng để suy luận.\nCác bước tinh chỉnh và suy luận nói trên cũng có thể được thực hiện theo chương trình. Để biết thêm thông tin, hãy tham khảo kho lưu trữ GitHub sau đây, trong đó chứa mã mẫu.\nKhung đánh giá và kết quả Trong phần này, trước tiên chúng tôi giới thiệu khung đánh giá nhiều thẩm phán LLM của chúng tôi, được thiết lập để giảm thiểu sự thiên vị của từng giám khảo LLM. Sau đó, chúng tôi so sánh RAG và kết quả tinh chỉnh về chất lượng phản hồi cũng như độ trễ và ý nghĩa của token.\nNhiều LLM làm thẩm phán để giảm thiểu thành kiến Sơ đồ sau đây minh họa quy trình làm việc của chúng tôi bằng cách sử dụng nhiều LLM làm giám khảo.\nSử dụng LLM làm giám khảo đã trở thành một cách tiếp cận ngày càng phổ biến để đánh giá các nhiệm vụ khó đánh giá thông qua các phương pháp truyền thống hoặc đánh giá của con người. Đối với khung đánh giá của mình, chúng tôi đã xây dựng 10 câu hỏi kiểm tra theo lĩnh vực cụ thể bao gồm các khía cạnh chính của các dịch vụ và tính năng AWS, được thiết kế để kiểm tra cả độ chính xác thực tế và chiều sâu hiểu biết. Mỗi câu trả lời do mô hình tạo ra được đánh giá bằng cách sử dụng hệ thống tính điểm tiêu chuẩn trên thang điểm 0–10, trong đó 0–3 biểu thị thông tin không chính xác hoặc gây hiểu lầm, 4–6 đại diện cho câu trả lời đúng một phần nhưng không đầy đủ, 7–8 biểu thị hầu hết đúng với những điểm không chính xác nhỏ và 9–10 biểu thị hoàn toàn chính xác với lời giải thích toàn diện.\nChúng tôi sử dụng lời nhắc đánh giá thẩm phán LLM sau:\n{\n\u0026quot;system\\_prompt\u0026quot;: \u0026quot;You are a helpful assistant.\u0026quot;, \u0026quot;prompt\\_template\u0026quot;: \u0026quot;\\[Instruction\\] Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question displayed below. Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response. Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: \\\\\u0026quot;\\[\\[rating\\]\\]\\\\\u0026quot;, for example: \\\\\u0026quot;Rating: \\[\\[5\\]\\]\\\\\u0026quot;.\\\\n\\\\n\\[Question\\]\\\\n{question}\\\\n\\\\n\\[The Start of Assistant's Answer\\]\\\\n{answer}\\\\n\\[The End of Assistant's Answer\\]\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;Prompt for general questions\u0026quot;, \u0026quot;category\u0026quot;: \u0026quot;general\u0026quot;, \u0026quot;output\\_format\u0026quot;: \u0026quot;\\[\\[rating\\]\\]\u0026quot; }\nChúng tôi sử dụng câu hỏi đánh giá mẫu sau đây và sự thật cơ bản:\n{\n\u0026quot;question\\_id\u0026quot;: 9161, \u0026quot;category\u0026quot;: \u0026quot;AWS\u0026quot;, \u0026quot;turns\u0026quot;: \\[ \u0026quot; \\\\\u0026quot;What specific details are collected and sent to AWS when anonymous operational metrics are enabled for an Amazon EFS file system?\u0026quot;, \u0026quot;What's required for a successful AWS CloudFormation launch?\u0026quot; \\], \u0026quot;reference\u0026quot;: \\[ \u0026quot;When anonymous operational metrics are enabled for an Amazon EFS file system, the following specific details are collected and sent to AWS: Solution ID, Unique ID, Timestamp, Backup ID, Backup Start Time, Backup Stop Time, Backup Window, Source EFS Size, Destination EFS Size, Instance Type, Retain, S3 Bucket Size, Source Burst Credit Balance, Source Burst Credit Balance Post Backup, Source Performance Mode, Destination Performance Mode, Number of Files, Number of Files Transferred, Total File Size, Total Transferred File Size, Region, Create Hard Links Start Time, Create Hard Links Stop Time, Remove Snapshot Start Time, Remove Snapshot Stop Time, Rsync Delete Start Time, Rsync Delete Stop Time.\u0026quot;, \u0026quot;For a successful AWS CloudFormation launch, you need to sign in to the AWS Management Console, choose the correct AWS Region, use the button to launch the template, verify the correct template URL, assign a name to your solution stack, review and modify the parameters as necessary, review and confirm the settings, check the boxes acknowledging that the template creates AWS Identity and Access Management resources and may require an AWS CloudFormation capability, and choose Create stack to deploy the stack. You should receive a CREATE\\_COMPLETE status in approximately 15 minutes.\u0026quot; \\] }\nĐể giảm thiểu những thành kiến nội tại tiềm ẩn giữa các giám khảo LLM khác nhau, chúng tôi đã sử dụng hai giám khảo LLM để đánh giá các phản hồi do mô hình tạo ra: Claude Sonnet 3.5 của Anthropic và Llama 3.1 70B của Meta. Mỗi giám khảo được cung cấp câu hỏi kiểm tra ban đầu, câu trả lời do mô hình tạo ra và các tiêu chí chấm điểm cụ thể tập trung vào độ chính xác, đầy đủ, liên quan và rõ ràng thực tế. Nhìn chung, chúng tôi quan sát thấy mức độ tương quan xếp hạng cao giữa các giám khảo LLM trong việc đánh giá các cách tiếp cận khác nhau, với các mô hình đánh giá nhất quán trên tất cả các trường hợp thử nghiệm.\nSo sánh chất lượng phản hồi Cả tinh chỉnh và RAG đều cải thiện đáng kể chất lượng câu trả lời được tạo cho các câu hỏi dành riêng cho AWS so với mô hình cơ sở. Sử dụng Amazon Nova Lite làm mô hình cơ sở, chúng tôi quan sát thấy rằng cả tinh chỉnh và RAG đều cải thiện 30% điểm trung bình của giám khảo LLM về chất lượng phản hồi, trong khi kết hợp tinh chỉnh với RAG đã cải thiện tổng cộng 83% chất lượng phản hồi, như thể hiện trong hình sau.\nĐáng chú ý, đánh giá của chúng tôi đã tiết lộ một phát hiện thú vị (như thể hiện trong hình sau): khi kết hợp các phương pháp tinh chỉnh và RAG, các mô hình nhỏ hơn như Amazon Nova Micro cho thấy những cải thiện đáng kể về hiệu suất trong các tác vụ theo miền cụ thể, gần như phù hợp với hiệu suất của các mô hình lớn hơn. Điều này cho thấy rằng đối với các trường hợp sử dụng chuyên biệt với phạm vi được xác định rõ ràng, sử dụng các mô hình nhỏ hơn với cả tinh chỉnh và RAG có thể là một giải pháp hiệu quả hơn về chi phí so với việc triển khai các mô hình lớn hơn.\nĐộ trễ và ý nghĩa của token Ngoài việc nâng cao chất lượng phản hồi, cả tinh chỉnh và RAG đều giúp giảm độ trễ tạo phản hồi so với mô hình cơ sở. Đối với cả Amazon Nova Micro và Amazon Nova Lite, tinh chỉnh đã giảm độ trễ của mô hình cơ sở khoảng 50%, trong khi RAG giảm khoảng 30%, như thể hiện trong hình sau.\nTinh chỉnh cũng thể hiện lợi thế độc đáo của việc cải thiện giọng điệu và phong cách của các câu trả lời được tạo để phù hợp hơn với dữ liệu đào tạo. Trong các thử nghiệm của chúng tôi, tổng số token trung bình (token đầu vào và đầu ra) giảm hơn 60% với cả hai mô hình được tinh chỉnh. Tuy nhiên, tổng số token trung bình tăng hơn gấp đôi với cách tiếp cận RAG do chuyển ngữ cảnh, như thể hiện trong hình sau. Phát hiện này cho thấy rằng đối với các trường hợp sử dụng nhạy cảm với độ trễ hoặc khi mục tiêu là điều chỉnh phản hồi của mô hình theo giọng điệu, phong cách hoặc giọng nói thương hiệu cụ thể, tùy chỉnh mô hình có thể mang lại nhiều giá trị kinh doanh hơn.\nKết thúc Trong bài đăng này, chúng tôi đã so sánh tùy chỉnh mô hình (tinh chỉnh) và RAG cho các tác vụ theo miền cụ thể với Amazon Nova. Trước tiên, chúng tôi cung cấp hướng dẫn chi tiết về cách tinh chỉnh, lưu trữ và tiến hành suy luận với Amazon Nova tùy chỉnh thông qua API Amazon Bedrock. Sau đó, chúng tôi áp dụng phương pháp LLM-as-a-judge để đánh giá chất lượng phản hồi từ các cách tiếp cận khác nhau. Ngoài ra, chúng tôi đã kiểm tra độ trễ và ý nghĩa mã thông báo của các thiết lập khác nhau.\nCả tinh chỉnh và RAG đều cải thiện hiệu suất của mô hình. Tùy thuộc vào nhiệm vụ và tiêu chí đánh giá, tùy chỉnh mô hình cho thấy hiệu suất tương tự hoặc đôi khi tốt hơn so với RAG. Tùy chỉnh mô hình cũng có thể hữu ích để cải thiện phong cách và giọng điệu của câu trả lời được tạo. Trong thử nghiệm này, phản hồi của mô hình tùy chỉnh tuân theo kiểu câu trả lời ngắn gọn của dữ liệu đào tạo đã cho, dẫn đến độ trễ thấp hơn so với đối tác cơ sở. Ngoài ra, tùy chỉnh mô hình cũng có thể được sử dụng cho nhiều trường hợp sử dụng mà RAG không đơn giản để sử dụng, chẳng hạn như gọi công cụ, phân tích cảm xúc, trích xuất thực thể, v.v. Nhìn chung, chúng tôi khuyên bạn nên kết hợp tùy chỉnh mô hình và RAG để trả lời câu hỏi hoặc các tác vụ tương tự để tối đa hóa hiệu suất.\nĐể biết thêm thông tin về Amazon Bedrock và các mẫu Amazon Nova mới nhất, hãy tham khảo Hướng dẫn sử dụng Amazon Bedrock và Hướng dẫn sử dụng Amazon Nova. Trung tâm đổi mới AI tổng quát AWS có một nhóm các chuyên gia khoa học và chiến lược AWS có chuyên môn toàn diện trong hành trình AI tổng quát, giúp khách hàng ưu tiên các trường hợp sử dụng, xây dựng lộ trình và đưa các giải pháp vào sản xuất. Hãy xem Trung tâm Đổi mới AI Tổng quát để biết những câu chuyện thành công mới nhất của chúng tôi về công việc và khách hàng.\nGiới thiệu về các tác giả\nẢnh đại diện Giới thiệu về các tác giả Mengdie (Flora) Wang là Nhà khoa học dữ liệu tại Trung tâm đổi mới AI tổng quát AWS, nơi cô làm việc với khách hàng để kiến trúc và triển khai các giải pháp AI tổng quát có thể mở rộng nhằm giải quyết những thách thức kinh doanh riêng của họ. Cô chuyên về các kỹ thuật tùy chỉnh mô hình và hệ thống AI dựa trên tác nhân, giúp các tổ chức khai thác toàn bộ tiềm năng của công nghệ AI tổng quát. Trước khi gia nhập AWS, Flora lấy bằng Thạc sĩ Khoa học Máy tính tại Đại học Minnesota, nơi cô phát triển chuyên môn về máy học và trí tuệ nhân tạo. Sungmin Hong là Nhà khoa học ứng dụng cấp cao tại Trung tâm đổi mới AI tổng quát của Amazon, nơi ông giúp đẩy nhanh sự đa dạng của các trường hợp sử dụng của khách hàng AWS. Trước khi gia nhập Amazon, Sungmin là nghiên cứu sinh sau tiến sĩ tại Trường Y Harvard. Ông có bằng Tiến sĩ Khoa học Máy tính tại Đại học New York. Ngoài công việc, anh ấy tự hào về việc giữ cho cây trồng trong nhà của mình tồn tại trong 3+ năm. Jae Oh Woo là Nhà khoa học ứng dụng cấp cao tại Trung tâm đổi mới AI tổng quát AWS, nơi anh chuyên phát triển các giải pháp tùy chỉnh và tùy chỉnh mô hình cho nhiều trường hợp sử dụng khác nhau. Ông có niềm đam mê mãnh liệt đối với nghiên cứu liên ngành kết nối nền tảng lý thuyết với các ứng dụng thực tế trong lĩnh vực AI tổng quát đang phát triển nhanh chóng. Trước khi gia nhập Amazon, Jae Oh là nghiên cứu sinh sau tiến sĩ Simons tại Đại học Texas ở Austin, nơi ông tiến hành nghiên cứu trên các khoa Toán học và Kỹ thuật Điện và Máy tính. Ông có bằng Tiến sĩ về Toán ứng dụng tại Đại học Yale. Rahul Ghosh là Nhà khoa học ứng dụng tại Trung tâm đổi mới AI tổng quát của Amazon, nơi ông làm việc với khách hàng AWS trên các ngành dọc khác nhau để đẩy nhanh việc sử dụng AI tổng quát. Rahul có bằng Tiến sĩ Khoa học Máy tính tại Đại học Minnesota. Baishali Chaudhury là Nhà khoa học ứng dụng tại Trung tâm Đổi mới AI Tổng quát tại AWS, nơi cô tập trung vào việc thúc đẩy các giải pháp AI tổng quát cho các ứng dụng trong thế giới thực. Cô có nền tảng vững chắc về thị giác máy tính, học máy và AI cho chăm sóc sức khỏe. Baishali có bằng Tiến sĩ Khoa học Máy tính của Đại học Nam Florida và PostDoc của Trung tâm Ung thư Moffitt. Anila Joshi có hơn một thập kỷ kinh nghiệm xây dựng các giải pháp AI. Với tư cách là Nhà lãnh đạo địa lý AWSI tại Trung tâm đổi mới AI tổng quát AWS, Anila đi tiên phong trong các ứng dụng sáng tạo của AI nhằm vượt qua ranh giới khả năng và đẩy nhanh việc áp dụng các dịch vụ AWS với khách hàng bằng cách giúp khách hàng lên ý tưởng, xác định và triển khai các giải pháp AI tổng quát bảo mật. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Di chuyển ứng dụng CDK phiên bản 1 sang CDK phiên bản 2 với Amazon Q Developer bởi Tiến sĩ Rahul Sharad Gaikwad, Tamilselvan P và Vinodkumar Mandalapu vào ngày 30 tháng 4 năm 2025 trên Amazon Q.\nGiới thiệu: Bộ công cụ phát triển đám mây AWS (AWS CDK) là một khung phát triển phần mềm mã nguồn mở để xác định cơ sở hạ tầng đám mây trong mã và cung cấp thông qua AWS CloudFormation. Kể từ ngày 1 tháng 6 năm 2023, AWS CDK phiên bản 1 không còn được hỗ trợ. Để tránh các vấn đề tiềm ẩn khi sử dụng phiên bản lỗi thời và tận dụng các tính năng và cải tiến mới nhất, chúng tôi khuyên bạn nên nâng cấp lên AWS CDK phiên bản 2.\nAmazon Q Developer, một trợ lý tổng quát được hỗ trợ bởi AI để phát triển phần mềm, nâng cao hiệu quả của các nhóm phát triển phần mềm. Nó tạo điều kiện thuận lợi cho việc tạo cơ sở hạ tầng sẵn sàng triển khai dưới dạng mã (IaC) cho AWS CloudFormation, AWS CDK và Terraform. Bằng cách sử dụng Amazon Q, các nhà phát triển có thể tăng tốc phát triển IaC, nâng cao chất lượng mã và giảm khả năng xảy ra lỗi cấu hình.\nBài đăng này trình bày cách Amazon Q Developer hỗ trợ nâng cấp ứng dụng AWS CDK v1 hiện có lên AWS CDK v2.\nĐiều kiện tiên quyết ID AWS Builder hoặc thông tin đăng nhập Trung tâm nhận dạng AWS IAM do tổ chức của bạn kiểm soát\nIDE được hỗ trợ, chẳng hạn như Visual Studio Code\nTiện ích mở rộng IDE của Bộ công cụ AWS\nXác thực và kết nối\nNodejs\nAWS CDK phiên bản 1\nAWS CDK phiên bản 2\nKế hoạch Trong bài đăng trên blog này, tôi sẽ khám phá một ví dụ về mã mà tôi đã tạo VPC, Mạng con và cụm ECS Fargate bằng AWS CDK phiên bản 1. Sau đó, tôi sẽ giải thích cách bạn có thể sử dụng Amazon Q để chuyển đổi mã từ CDK v1 sang CDK v2.\n1. Để bắt đầu quá trình này, tôi đã bắt đầu bằng cách yêu cầu Nhà phát triển Amazon Q cung cấp các bước cần thiết để di chuyển từ CDK phiên bản 1 sang phiên bản 2, được nêu dưới đây.\nCan you provide the steps to migrate from cdk version 1 to version 2?\n2. Trong ảnh chụp màn hình trên, Amazon Q Developer đã phác thảo một số bước chúng tôi có thể thực hiện để thực hiện các thay đổi cần thiết. Bước đầu tiên là cập nhật các phần phụ thuộc. Nếu tôi cần hướng dẫn về cách cập nhật các phần phụ thuộc, tôi có thể yêu cầu Nhà phát triển Amazon Q trợ giúp một lần nữa bằng cách yêu cầu các bước liên quan đến cập nhật các phần phụ thuộc như bên dưới.\nCan you provide the steps to update dependencies?\n3. Sau khi cập nhật các phần phụ thuộc, bước tiếp theo là cập nhật các câu lệnh nhập. Để được hướng dẫn về cách cập nhật các câu lệnh nhập, tôi có thể yêu cầu trợ lý nhà phát triển Amazon Q trợ giúp một lần nữa bằng cách hỏi các bước liên quan đến cách nhập các câu lệnh như hình dưới đây.\n@workspace Can you provide the steps to update import statements?\nTrong ảnh chụp màn hình ở trên, nếu bạn nhận thấy, tôi đã thêm trước câu hỏi tự động bao gồm các phần có liên quan nhất của mã không gian làm việc của tôi dưới dạng ngữ cảnh.@workspace\n4. Nếu có bất kỳ lỗi nào xảy ra trong khi cập nhật mã theo khuyến nghị của Amazon Q Developer, tôi có thể sử dụng Amazon Q Developer để gỡ lỗi sự cố và cung cấp thông tin đầu vào cần thiết để giải quyết.\n5. Sau khi hoàn thành các bước bắt buộc, tôi có thể triển khai ứng dụng bằng phiên bản 2 của AWS CDK bằng cách chạy lệnh.cdk deploy\n6. Ngoài các khả năng khác, Amazon Q còn cung cấp chức năng xem xét mã. Để bắt đầu xem xét mã, chỉ cần chọn Amazon Q và sử dụng lệnh. Sau đó, tôi sẽ có tùy chọn để xem lại các tệp đang hoạt động hoặc toàn bộ không gian làm việc đang mở. Chọn tùy chọn của bạn và Amazon Q sẽ phân tích dự án của bạn và cung cấp kết quả đánh giá toàn diện./review\n7. Amazon Q Developer cũng có thể tạo tài liệu, bao gồm các tệp README. Để tạo tài liệu, hãy chọn Amazon Q và nhập lệnh. Amazon Q sẽ tự động tạo tệp README cho dự án của bạn. Sau đó, tôi có thể xem lại tài liệu đã tạo, chấp nhận các thay đổi hoặc cung cấp hướng dẫn cụ thể để sửa đổi thêm./doc\nKết thúc Trong blog này, tôi đã trình bày cách Amazon Q Developer có thể đơn giản hóa và đẩy nhanh quá trình nâng cấp từ AWS CDK phiên bản 1 lên phiên bản 2, đảm bảo cơ sở hạ tầng đám mây của bạn luôn bảo mật, hiệu quả và phù hợp với những cải tiến mới nhất của AWS. AWS CDK phiên bản 2 cung cấp một thư viện hợp nhất, hợp nhất được sắp xếp hợp lý với hiệu suất được cải thiện và hỗ trợ liên tục, giúp việc quản lý cơ sở hạ tầng trở nên dễ dàng và đáng tin cậy hơn.\nBằng cách tận dụng Amazon Q Developer, một trợ lý tổng quát được hỗ trợ bởi AI, các nhóm có thể tự động hóa việc phát triển Cơ sở hạ tầng dưới dạng mã, nâng cao chất lượng mã và giảm thiểu lỗi cấu hình. Cùng với nhau, các công cụ này hỗ trợ các nhóm phát triển tự tin hiện đại hóa và mở rộng quy mô môi trường AWS của họ, biến quá trình nâng cấp thành cơ hội liền mạch để đổi mới và tăng trưởng.\nTài nguyên Để tìm hiểu thêm về Amazon Q Developer, hãy xem các tài nguyên sau:\nHội thảo dành cho nhà phát triển Amazon Q\nHướng dẫn sử dụng nhà phát triển Amazon Q\nĐể tìm hiểu thêm về AWS CDK, hãy xem các tài nguyên sau:\nHội thảo AWS CDK\nCách sử dụng Amazon Q Developer để triển khai ứng dụng web phi máy chủ với AWS CDK\nGiới thiệu về các tác giả:\nẢnh đại diện Giới thiệu về các tác giả Tiến sĩ Rahul Sharad Gaikwad là Kiến trúc sư giải pháp tại AWS, thúc đẩy đổi mới đám mây thông qua việc di chuyển và hiện đại hóa khối lượng công việc của khách hàng. Là một người đam mê Generative AI và DevOps, anh ấy kiến trúc các giải pháp tiên tiến và được công nhận là Đại sứ APJC HashiCorp. Ông lấy bằng tiến sĩ về AIOps và ông đã nhận được Giải thưởng Người đàn ông xuất sắc, Giải thưởng Người thành tựu Ấn Độ, Giải thưởng Luận án Tiến sĩ Xuất sắc nhất, Giải thưởng Học giả Nghiên cứu của Năm và Giải thưởng Nhà nghiên cứu trẻ. Vinodkumar Mandalapu là Chuyên gia tư vấn Devops tại AWS, chuyên thiết kế và triển khai cơ sở hạ tầng dựa trên đám mây và đường ống triển khai trên AWS. Với kinh nghiệm dày dặn trong việc tự động hóa và hợp lý hóa việc phân phối phần mềm, ông đã giúp các tổ chức thuộc mọi quy mô tận dụng sức mạnh của đám mây để thúc đẩy đổi mới, cải thiện khả năng mở rộng và nâng cao hiệu quả hoạt động. Trong thời gian rảnh rỗi, anh ấy thích đi du lịch và dành thời gian chất lượng cho con trai mình. Tamilselvan P là Chuyên gia tư vấn Devops tại AWS, tập trung vào việc kiến trúc và triển khai các hệ thống gốc đám mây cũng như phân phối liên tục trong hệ sinh thái. Tận dụng chuyên môn toàn diện của mình trong việc điều phối và tinh chỉnh các quy trình phát hành phần mềm, ông đã hỗ trợ khách hàng trong nhiều ngành và quy mô khác nhau trong việc khai thác công nghệ đám mây để đổi mới nhanh hơn, tăng khả năng mở rộng và nâng cao hiệu suất hoạt động. Trong thời gian rảnh rỗi, anh ấy thích chơi cricket. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Melting The Ice - Cách Natural Intelligence đơn giản hóa việc chuyển đổi Data lake sang Apache Iceberg bởi Yonatan Dolan và Haya Axelrod Stern, Zion Rubin, Michal Urbanowicz vào 28 tháng 4 năm 2025 trong Advanced (300), Analytics, AWS Glue, Best Practices, Case Study, Technical How-to Permalink\nBài viết này được đồng tác giả bởi Haya Axelrod Stern, Zion Rubin và Michal Urbanowicz từ Natural Intelligence..\nNhiều tổ chức chọn data lake vì tính linh hoạt và khả năng mở rộng trong việc quản lý dữ liệu có cấu trúc và không cấu trúc. Tuy nhiên, việc di chuyển một data lake hiện hữu sang định dạng bảng mới như Apache Iceberg có thể gặp nhiều thách thức về kỹ thuật lẫn tổ chức.\nNatural Intelligence (NI) là một đơn vị hàng đầu trong lĩnh vực thị trường đa danh mục. Với các thương hiệu nổi bật như Top10.com và BestMoney.com, NI hỗ trợ hàng triệu người mỗi ngày trong việc đưa ra quyết định thông minh. Gần đây, NI đã khởi động hành trình chuyển đổi data lake truyền thống từ Apache Hive sang Apache Iceberg.\nTrong bài viết này, NI chia sẻ hành trình của họ, các giải pháp sáng tạo đã phát triển, và những bài học chính có thể hướng dẫn các tổ chức khác muốn thực hiện con đường tương tự. Nội dung tập trung nhiều vào thách thức thực tế và cách giải quyết trong quá trình chuyển đổi, hơn là các đặc tả kỹ thuật phức tạp của Apache Iceberg.\nTại sao chọn Apache Iceberg? Kiến trúc dữ liệu tại NI tuân theo mô hình Medallion Architecture (kiến trúc phân tầng đồng – bạc – vàng), được mô tả như sau:\nLớp Đồng (Bronze layer):\nDữ liệu thô chưa qua xử lý được thu thập từ nhiều nguồn khác nhau, lưu trữ ở định dạng gốc trong Amazon Simple Storage Service (Amazon S3) và được nạp thông qua Apache Kafka brokers.\nLớp Bạc (Silver layer):\nChứa dữ liệu đã được làm sạch và làm giàu (enriched data), được xử lý bằng Apache Flink.\nLớp Vàng (Gold layer):\nLưu trữ các tập dữ liệu sẵn sàng cho phân tích (analytics-ready datasets) được thiết kế cho Business Intelligence (BI) và báo cáo.\nDữ liệu ở lớp này được tạo ra thông qua các pipeline Apache Spark và được sử dụng bởi các dịch vụ như Snowflake, Amazon Athena, Tableau, và Apache Druid.\nDữ liệu được lưu ở định dạng Apache Parquet, với AWS Glue Catalog chịu trách nhiệm quản lý siêu dữ liệu (metadata management).\nMặc dù kiến trúc này đáp ứng được các nhu cầu phân tích dữ liệu của NI, nhưng nó thiếu tính linh hoạt cần thiết cho một nền tảng dữ liệu mở và có khả năng thích ứng thực sự.Lớp Gold chỉ có thể hoạt động với các công cụ truy vấn (query engines) hỗ trợ Hive và AWS Glue Data Catalog. Dù có thể sử dụng Amazon Athena, nhưng với Snowflake, NI phải duy trì một catalog riêng biệt để có thể truy vấn các bảng external (ngoại bảng). Vấn đề này khiến cho việc đánh giá hoặc áp dụng các công cụ và engine thay thế trở nên khó khăn — nếu không muốn nhân bản dữ liệu, viết lại truy vấn, hoặc đồng bộ lại catalog tốn kém chi phí. Khi quy mô kinh doanh mở rộng, NI cần một nền tảng dữ liệu có thể hỗ trợ đồng thời nhiều công cụ truy vấn khác nhau chỉ với một data catalog duy nhất, đồng thời tránh bị phụ thuộc vào bất kỳ nhà cung cấp nào (vendor lock-in).\nSức mạnh của Apache Iceberg Apache Iceberg nổi lên như một giải pháp hoàn hảo — một định dạng bảng mở, linh hoạt phù hợp với cách tiếp cận Data Lake First của NI. Iceberg cung cấp một số lợi thế quan trọng như giao dịch ACID, phát triển lược đồ, du hành thời gian, cải thiện hiệu suất và hơn thế nữa. Nhưng lợi ích chiến lược chính nằm ở khả năng hỗ trợ nhiều công cụ truy vấn đồng thời. Nó cũng có những ưu điểm sau:\nTách biệt giữa lưu trữ và xử lý (Decoupling of storage and compute): Định dạng bảng mở cho phép bạn tách lớp lưu trữ khỏi công cụ truy vấn, cho phép dễ dàng hoán đổi và hỗ trợ đồng thời nhiều công cụ mà không trùng lặp dữ liệu.\nĐộc lập với nhà cung cấp (Vendor independence) : Là một định dạng bảng mở, Apache Iceberg ngăn chặn khóa nhà cung cấp, giúp bạn linh hoạt thích ứng với nhu cầu phân tích thay đổi.\nĐược nhiều nền tảng hỗ trợ (Vendor adoption): Apache Iceberg được hỗ trợ rộng rãi bởi các nền tảng và công cụ chính, cung cấp khả năng tích hợp liền mạch và khả năng tương thích lâu dài với hệ sinh thái.\nBằng cách chuyển đổi sang Iceberg, NI đã có thể nắm bắt một nền tảng dữ liệu mở thực sự, cung cấp tính linh hoạt lâu dài, khả năng mở rộng và khả năng tương tác trong khi vẫn duy trì một nguồn tin cậy thống nhất cho tất cả các nhu cầu phân tích và báo cáo.\nNhững thách thức phải đối mặt Việc di chuyển hồ dữ liệu sản xuất trực tiếp sang Iceberg là một thách thức vì sự phức tạp trong hoạt động và các hạn chế kế thừa. Dịch vụ dữ liệu tại NI chạy hàng trăm quy trình Spark và machine learning, quản lý hàng nghìn bảng và hỗ trợ hơn 400 bảng thông tin—tất cả đều hoạt động 24/7. Bất kỳ quá trình di chuyển nào cũng cần được thực hiện mà không bị gián đoạn sản xuất; và việc điều phối một cuộc di cư như vậy trong khi các hoạt động tiếp tục liền mạch là điều khó khăn.\nNI cần đáp ứng những người dùng đa dạng với các yêu cầu và thời gian khác nhau từ kỹ sư dữ liệu đến nhà phân tích dữ liệu cho đến các nhà khoa học dữ liệu và nhóm BI.\nThêm vào thách thức là những hạn chế kế thừa. Một số công cụ hiện có không hỗ trợ đầy đủ Iceberg, vì vậy cần phải duy trì các bảng được hỗ trợ bởi Hive để tương thích. Khi NI nhận ra rằng không phải tất cả người tiêu dùng đều có thể chấp nhận Iceberg ngay lập tức. Cần có một kế hoạch để cho phép chuyển đổi gia tăng mà không có thời gian ngừng hoạt động hoặc gián đoạn các hoạt động đang diễn ra.\nCác thành phần chính cho quá trình di chuyển Để đảm bảo quá trình chuyển đổi diễn ra suôn sẻ và thành công, sáu thành phần quan trọng đã được xác định như sau:\nDuy trì hoạt động liên tục (Support ongoing operations):\nĐảm bảo khả năng tương thích không bị gián đoạn với các hệ thống và quy trình hiện có trong suốt quá trình di chuyển.\nTính minh bạch với người dùng (User transparency):\nGiảm thiểu gián đoạn cho người dùng bằng cách giữ nguyên tên bảng và cách truy cập như cũ.\nChuyển đổi người dùng dần dần (Gradual consumer migration):\nCho phép người dùng chuyển sang Iceberg theo tiến độ riêng, tránh việc phải chuyển đổi đồng loạt cùng lúc.\nTính linh hoạt trong ETL (ETL flexibility):\nCho phép chuyển các pipeline ETL sang Iceberg mà không áp đặt các ràng buộc trong quá trình phát triển hoặc triển khai.\nHiệu quả chi phí (Cost effectiveness):\nGiảm thiểu nhân bản dữ liệu lưu trữ và xử lý, cũng như chi phí phát sinh trong giai đoạn chuyển đổi.\nGiảm thiểu bảo trì (Minimize maintenance):\nGiảm gánh nặng vận hành trong việc duy trì song song hai định dạng bảng (Hive và Iceberg) trong quá trình chuyển đổi.\nĐánh giá các phương pháp di chuyển truyền thống Apache Iceberg hỗ trợ hai phương pháp chính để di chuyển dữ liệu In-place migration (Chuyển đổi trực tiếp) và Rewrite-based migration (Chuyển đổi bằng cách ghi lại dữ liệu).\nChuyển đổi trực tiếp (In-place migration)\nCách hoạt động: Phương pháp này chuyển đổi bộ dữ liệu hiện có sang bảng Iceberg mà không cần nhân bản dữ liệu, bằng cách tạo metadata của Iceberg dựa trên các tệp dữ liệu hiện có, đồng thời giữ nguyên bố cục và định dạng ban đầu.\nƯu điểm:\nTiết kiệm chi phí lưu trữ, vì không có sự nhân bản dữ liệu.\nDễ triển khai, quá trình thực hiện đơn giản.\nGiữ nguyên tên và vị trí bảng hiện tại, giúp người dùng không phải thay đổi truy cập.\nKhông cần di chuyển dữ liệu, yêu cầu tính toán tối thiểu → chi phí thấp hơn.\nNhược điểm:\nCần downtime: Tất cả các thao tác ghi phải tạm dừng trong khi chuyển đổi, điều này không thể chấp nhận được với NI, vì các quy trình dữ liệu và phân tích rất quan trọng và vận hành 24/7.\nKhông thể chuyển đổi dần dần: Tất cả người dùng phải chuyển sang Iceberg cùng lúc, làm tăng nguy cơ gián đoạn hệ thống.\nGiới hạn xác thực: Không có cơ hội kiểm tra tính đúng đắn của dữ liệu trước khi hoàn tất chuyển đổi; nếu có lỗi, cần phục hồi từ bản sao lưu.\nHạn chế kỹ thuật: Việc tiến hóa schema trong quá trình chuyển đổi có thể khó khăn; xung đột kiểu dữ liệu có thể khiến toàn bộ quy trình thất bại.\nRewrite-based migration (Chuyển đổi bằng cách ghi lại dữ liệu) Cách hoạt động: Phương pháp này tạo một bảng Iceberg mới bằng cách viết lại và tái tổ chức các tệp dữ liệu hiện có theo định dạng và cấu trúc tối ưu của Iceberg, giúp cải thiện hiệu năng và quản lý dữ liệu.\nƯu điểm:\nKhông cần downtime trong suốt quá trình di chuyển.\nHỗ trợ chuyển đổi người dùng dần dần, cho phép từng nhóm áp dụng Iceberg theo nhịp riêng.\nCho phép xác thực dữ liệu kỹ lưỡng trước khi chuyển đổi hoàn toàn.\nCơ chế rollback đơn giản, có thể dễ dàng quay lại nếu có lỗi.\nNhược điểm:\nTăng chi phí tài nguyên: Cần gấp đôi dung lượng lưu trữ và công suất xử lý trong thời gian di chuyển.\nPhức tạp trong bảo trì: Cần duy trì hai pipeline dữ liệu song song, tăng gánh nặng vận hành.\nThách thức về tính nhất quán: Khó đảm bảo hai hệ thống luôn đồng bộ hoàn toàn trong thời gian chuyển đổi.\nẢnh hưởng đến hiệu năng: Ghi dữ liệu song song (dual writes) có thể tăng độ trễ và làm chậm pipeline.\nTại sao không phương án nào là đủ tốt NI nhận thấy rằng cả hai phương pháp (In-place và Rewrite-based) đều không thể đáp ứng đầy đủ các yêu cầu quan trọng:\nIn-place migration không phù hợp vì yêu cầu downtime (ngừng hoạt động) là không thể chấp nhận được, và không hỗ trợ quá trình chuyển đổi dần dần.\nRewrite-based migration lại tốn kém chi phí và phức tạp trong quản lý vận hành do phải duy trì hai pipeline song song.\nTừ những phân tích đó, NI đã phát triển một giải pháp lai (hybrid approach) — kết hợp ưu điểm của cả hai phương pháp, đồng thời giảm thiểu và khắc phục các hạn chế của chúng.\nGiải pháp Hybrid Chiến lược di chuyển lai được thiết kế dựa trên 5 thành phần cốt lõi, tận dụng các dịch vụ phân tích của AWS để điều phối, xử lý và quản lý trạng thái.\n1. Hive-to-Iceberg CDC (Đồng bộ thay đổi từ Hive sang Iceberg): Hệ thống tự động đồng bộ các bảng Hive sang Iceberg bằng quy trình CDC (Change Data Capture) tùy chỉnh để hỗ trợ người dùng hiện có. Không giống CDC truyền thống theo mức hàng (row-level), NI áp dụng CDC ở mức phân vùng (partition-level) — vì Hive thường cập nhật dữ liệu bằng cách ghi đè (overwrite) toàn bộ phân vùng. Cách này giúp duy trì tính nhất quán dữ liệu giữa Hive và Iceberg mà không cần thay đổi logic ghi dữ liệu, đảm bảo rằng hai bảng chứa cùng dữ liệu trong giai đoạn di chuyển. 2. Continuous schema synchronization (Đồng bộ lược đồ liên tục): Trong quá trình di chuyển, việc tiến hóa schema (schema evolution) gây ra nhiều thách thức trong bảo trì. NI triển khai quy trình đồng bộ lược đồ tự động, so sánh schema giữa Hive và Iceberg, và điều chỉnh sự khác biệt trong khi vẫn giữ tương thích kiểu dữ liệu (type compatibility). 3. Iceberg-to-Hive reverse CDC (Đồng bộ ngược từ Iceberg sang Hive): Cho phép nhóm dữ liệu chuyển các job ETL (Extract, Transform, Load) để ghi trực tiếp vào Iceberg, đồng thời vẫn duy trì tính tương thích với các quy trình cũ dùng Hive. Reverse CDC giúp tự động cập nhật dữ liệu từ Iceberg ngược trở lại Hive, đảm bảo các pipeline downstream (phía sau) chưa di chuyển vẫn hoạt động bình thường. Nhờ đó, hệ thống có thể chuyển đổi dần dần, không làm gián đoạn quy trình hiện có. 4. Alias management in Snowflake (Quản lý bí danh trong Snowflake): Sử dụng alias (bí danh) trong Snowflake để đảm bảo rằng các bảng Iceberg giữ nguyên tên gốc, giúp quá trình chuyển đổi trở nên trong suốt (transparent) đối với người dùng. Cách này giúp giảm thiểu việc cấu hình lại trên các nhóm phụ thuộc và các workflow hiện có. 5. Table replacement (Thay thế bảng sản xuất): Sau khi toàn bộ hệ thống đã chuyển sang Iceberg, NI hoán đổi (swap) các bảng sản xuất, giữ nguyên tên bảng ban đầu, và hoàn tất quá trình di chuyển. Tìm hiểu sâu về kỹ thuật Quá trình di chuyển từ Hive đến Iceberg được xây dựng từ một số bước:\n1. Sơ đồ Hive-to-Iceberg CDC: Mục tiêu: Giữ cho bảng Hive và Iceberg được đồng bộ hóa mà không cần nỗ lực trùng lặp.\nHình trước cho thấy cách mọi phân vùng được ghi vào bảng Hive được sao chép tự động và minh bạch vào bảng Iceberg bằng cách sử dụng quy trình CDC. Quá trình này đảm bảo rằng cả hai bảng đều được đồng bộ hóa, cho phép di chuyển liền mạch và gia tăng mà không làm gián đoạn hệ thống xuôi dòng. NI đã chọn đồng bộ hóa cấp phân vùng vì các công việc Hive ETL cũ đã ghi các bản cập nhật bằng cách ghi đè lên toàn bộ phân vùng và cập nhật vị trí phân vùng. Việc áp dụng cách tiếp cận tương tự trong quy trình CDC đã giúp đảm bảo rằng nó vẫn nhất quán với cách dữ liệu được quản lý ban đầu, giúp quá trình di chuyển suôn sẻ hơn và tránh phải làm lại logic cấp hàng.\nThực hiện:\nĐể giữ cho bảng Hive và Iceberg được đồng bộ hóa mà không cần nỗ lực trùng lặp, một quy trình hợp lý đã được triển khai. Bất cứ khi nào các phân vùng trong bảng Hive được cập nhật, AWS Glue Catalog sẽ phát ra các sự kiện như . Amazon EventBridge đã nắm bắt các sự kiện này, lọc chúng cho các cơ sở dữ liệu và bảng có liên quan theo quy tắc cầu nối sự kiện, đồng thời kích hoạt AWS Lambda Hàm này phân tích siêu dữ liệu sự kiện và gửi các bản cập nhật phân vùng đến chủ đề Apache Kafka.UpdatePartition\nMột tác vụ Spark chạy trên Amazon EMR đã sử dụng các tin nhắn từ Kafka, chứa các chi tiết phân vùng được cập nhật từ các sự kiện Danh mục dữ liệu. Sử dụng siêu dữ liệu sự kiện đó, tác vụ Spark truy vấn bảng Hive có liên quan và ghi vào bảng Iceberg trong Amazon S3 bằng API Spark Iceberg, như được hiển thị trong ví dụ sau:overwritePartitions\n{\n\u0026quot;id\u0026quot;: \u0026quot;10397e54-c049-fc7b-76c8-59e148c7cbfc\u0026quot;, \u0026quot;detail-type\u0026quot;: \u0026quot;Glue Data Catalog Table State Change\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;aws.glue\u0026quot;, \u0026quot;time\u0026quot;: \u0026quot;2024-10-27T17:16:21Z\u0026quot;, \u0026quot;region\u0026quot;: \u0026quot;us-east-1\u0026quot;, \u0026quot;detail\u0026quot;: { \u0026quot;databaseName\u0026quot;: \u0026quot;dlk\\_visitor\\_funnel\\_dwh\\_production\u0026quot;, \u0026quot;changedPartitions\u0026quot;: \\[ \u0026quot;2024-10-27\u0026quot; \\], \u0026quot;typeOfChange\u0026quot;: \u0026quot;UpdatePartition\u0026quot;, \u0026quot;tableName\u0026quot;: \u0026quot;fact\\_events\u0026quot; } }\nBằng cách chỉ nhắm mục tiêu các phân vùng đã sửa đổi, quy trình (được hiển thị trong hình sau) đã giảm đáng kể nhu cầu viết lại toàn bảng tốn kém. Các lớp siêu dữ liệu mạnh mẽ của Iceberg, bao gồm ảnh chụp nhanh và tệp kê khai, đã được cập nhật liền mạch để nắm bắt những thay đổi này, cung cấp đồng bộ hóa hiệu quả và chính xác giữa bảng Hive và Iceberg. 2. Sơ đồ ceberg-to-Hive reverse CDC Mục tiêu: Hỗ trợ khách hàng Hive đồng thời cho phép các quy trình ETL chuyển sang Iceberg.\nHình trước cho thấy quá trình ngược lại, trong đó mọi phân vùng được ghi vào bảng Iceberg được sao chép tự động và minh bạch vào bảng Hive bằng cơ chế CDC. Quá trình này giúp đảm bảo đồng bộ hóa giữa hai hệ thống, cho phép cập nhật dữ liệu liền mạch cho các hệ thống cũ vẫn dựa vào Hive trong khi chuyển sang Iceberg.\nThực hiện:\nĐồng bộ hóa dữ liệu từ bảng Iceberg trở lại bảng Hive đưa ra một thách thức khác. Không giống như bảng Hive, Danh mục dữ liệu không theo dõi các bản cập nhật phân vùng cho bảng Iceberg vì các phân vùng trong Iceberg được quản lý nội bộ chứ không phải trong danh mục. Điều này có nghĩa là NI không thể dựa vào các sự kiện Glue Catalog để phát hiện các thay đổi phân vùng.\nĐể giải quyết vấn đề này, NI đã triển khai một giải pháp tương tự như quy trình trước đó nhưng thích ứng với kiến trúc của Iceberg. Apache Spark được sử dụng để truy vấn các bảng siêu dữ liệu của Iceberg - cụ thể là các bảng ảnh chụp nhanh và mục nhập - để xác định các phân vùng được sửa đổi kể từ lần đồng bộ hóa cuối cùng. Truy vấn được sử dụng là:\nSELECT e.data_file.partition, MAX(s.committed_at) AS last_modified_time\nFROM $target_table.snapshots JOIN $target_table.entries e ON s.snapshot_id = e.snapshot_id\nWHERE s.committed_at \u0026amp;gt; \u0026lsquo;$last_sync_time\u0026rsquo;\nGROUP BY e.data_file.partition;\nTruy vấn này chỉ trả về các phân vùng đã được cập nhật kể từ lần đồng bộ hóa cuối cùng, cho phép nó tập trung hoàn toàn vào dữ liệu đã thay đổi. Sử dụng thông tin này, tương tự như quy trình trước đó, một công việc Spark đã truy xuất các phân vùng được cập nhật từ Iceberg và ghi chúng trở lại bảng Hive tương ứng, cung cấp sự đồng bộ hóa liền mạch giữa cả hai bảng.\n3. Đồng bộ hóa lược đồ liên tục Mục tiêu: tự động cập nhật lược đồ để duy trì tính nhất quán trên Hive và Iceberg.\nHình trước cho thấy quy trình đồng bộ hóa lược đồ tự động giúp đảm bảo tính nhất quán giữa lược đồ bảng Hive và Iceberg bằng cách tự động đồng bộ hóa các thay đổi lược đồ. Trong ví dụ này, thêm cột, giảm thiểu công việc thủ công và bảo trì kép trong thời gian di chuyển kéo dài.Channel\nThực hiện:\nĐể xử lý các thay đổi lược đồ giữa Hive và Iceberg, một quy trình đã được thực hiện để phát hiện và đối chiếu sự khác biệt một cách tự động. Khi thay đổi lược đồ xảy ra trong bảng Hive, Danh mục dữ liệu sẽ phát ra một sự kiện. Sự kiện này kích hoạt hàm Lambda (được định tuyến qua EventBridge), hàm này truy xuất lược đồ cập nhật từ Danh mục dữ liệu cho bảng Hive và so sánh với lược đồ Iceberg. Điều quan trọng cần lưu ý là trong thiết lập của NI, các thay đổi lược đồ bắt nguồn từ Hive vì bảng Iceberg được ẩn đằng sau các bí danh trên toàn hệ thống. Bởi vì Iceberg chủ yếu được sử dụng cho Snowflake, đồng bộ hóa một chiều từ Hive đến Iceberg là đủ. Do đó, không có cơ chế để phát hiện hoặc xử lý các thay đổi lược đồ được thực hiện trực tiếp trong Iceberg, vì chúng không cần thiết trong quy trình làm việc hiện tại.UpdateTable\nTrong quá trình đối chiếu lược đồ (hiển thị trong hình sau), các kiểu dữ liệu được chuẩn hóa để giúp đảm bảo khả năng tương thích — ví dụ: chuyển đổi Hive sang Iceberg . Mọi trường hoặc thay đổi loại mới đều được xác thực và áp dụng cho lược đồ Iceberg bằng cách sử dụng tác vụ Spark chạy trên Amazon EMR. Amazon DynamoDB lưu trữ các điểm kiểm tra đồng bộ hóa lược đồ cho phép theo dõi các thay đổi theo thời gian và duy trì tính nhất quán giữa lược đồ Hive và Iceberg.VARCHARSTRING\nTrong ví dụ này, thêm cột, giảm thiểu công việc thủ công và bảo trì kép trong thời gian di chuyển kéo dài.Channel\nThực hiện:\nĐể xử lý các thay đổi lược đồ giữa Hive và Iceberg, một quy trình đã được thực hiện để phát hiện và đối chiếu sự khác biệt một cách tự động. Khi thay đổi lược đồ xảy ra trong bảng Hive, Danh mục dữ liệu sẽ phát ra một sự kiện. Sự kiện này kích hoạt hàm Lambda (được định tuyến qua EventBridge), hàm này truy xuất lược đồ cập nhật từ Danh mục dữ liệu cho bảng Hive và so sánh với lược đồ Iceberg. Điều quan trọng cần lưu ý là trong thiết lập của NI, các thay đổi lược đồ bắt nguồn từ Hive vì bảng Iceberg được ẩn đằng sau các bí danh trên toàn hệ thống. Bởi vì Iceberg chủ yếu được sử dụng cho Snowflake, đồng bộ hóa một chiều từ Hive đến Iceberg là đủ. Do đó, không có cơ chế để phát hiện hoặc xử lý các thay đổi lược đồ được thực hiện trực tiếp trong Iceberg, vì chúng không cần thiết trong quy trình làm việc hiện tại.UpdateTable\nTrong quá trình đối chiếu lược đồ (hiển thị trong hình sau), các kiểu dữ liệu được chuẩn hóa để giúp đảm bảo khả năng tương thích — ví dụ: chuyển đổi Hive sang Iceberg . Mọi trường hoặc thay đổi loại mới đều được xác thực và áp dụng cho lược đồ Iceberg bằng cách sử dụng tác vụ Spark chạy trên Amazon EMR. Amazon DynamoDB lưu trữ các điểm kiểm tra đồng bộ hóa lược đồ cho phép theo dõi các thay đổi theo thời gian và duy trì tính nhất quán giữa lược đồ Hive và Iceberg.VARCHARSTRING\nBằng cách tự động hóa đồng bộ hóa lược đồ này, chi phí bảo trì đã giảm đáng kể và giải phóng các nhà phát triển khỏi việc đồng bộ hóa lược đồ theo cách thủ công, làm cho thời gian di chuyển dài dễ quản lý hơn đáng kể.\nHình trước mô tả quy trình làm việc tự động để duy trì tính nhất quán lược đồ giữa bảng Hive và Iceberg. AWS Glue ghi lại các sự kiện thay đổi trạng thái bảng từ Hive, kích hoạt sự kiện EventBridge. Sự kiện này gọi một hàm Lambda tìm nạp siêu dữ liệu từ DynamoDB và so sánh các lược đồ được tìm nạp từ AWS Glue cho cả bảng Hive và Iceberg. Nếu phát hiện sự không khớp, lược đồ trong Iceberg sẽ được cập nhật để giúp đảm bảo căn chỉnh, giảm thiểu sự can thiệp thủ công và hỗ trợ hoạt động trơn tru trong quá trình di chuyển.\n4. Quản lý bí danh trong Snowflake Mục tiêu: Cho phép người tiêu dùng Snowflake áp dụng Iceberg mà không cần thay đổi tham chiếu truy vấn.\nHình trước cho thấy bí danh Snowflake cho phép di chuyển liền mạch bằng cách ánh xạ các truy vấn như bảng Iceberg trong Glue Catalog. Ngay cả khi có thêm hậu tố trong quá trình di chuyển Iceberg, các truy vấn và quy trình làm việc hiện có vẫn không thay đổi, giảm thiểu sự gián đoạn cho các công cụ BI và nhà phân tích.SELECT platform, COUNT(clickouts) FROM funnel.clickouts\nThực hiện:\nĐể giúp đảm bảo trải nghiệm liền mạch cho các công cụ BI và nhà phân tích trong quá trình di chuyển, bí danh Snowflake đã được sử dụng để ánh xạ các bảng bên ngoài với siêu dữ liệu Iceberg được lưu trữ trong Danh mục dữ liệu. Bằng cách gán các bí danh khớp với tên bảng Hive ban đầu, các truy vấn và báo cáo hiện có đã được giữ nguyên mà không bị gián đoạn. Ví dụ: một bảng bên ngoài đã được tạo trong Snowflake và đặt bí danh thành tên bảng ban đầu, như được hiển thị trong truy vấn sau:\nCREATE OR REPLACE ICEBERG TABLE dlk\\_visitor\\_funnel\\_dwh\\_production.aggregated\\_cost EXTERNAL\\_VOLUME \\= 's3\\_dlk\\_visitor\\_funnel\\_dwh\\_production\\_iceberg\\_migration' CATALOG \\= 'glue\\_dlk\\_visitor\\_funnel\\_dwh\\_production\\_iceberg\\_migration' CATALOG\\_TABLE\\_NAME \\= 'aggregated\\_cost'; ALTER ICEBERG TABLE dlk\\_visitor\\_funnel\\_dwh\\_production.aggregated\\_cost REFRESH; Khi quá trình di chuyển hoàn tất, một thay đổi đơn giản trở lại bí danh đã được thực hiện để trỏ đến vị trí hoặc lược đồ mới, giúp quá trình chuyển đổi trở nên liền mạch và giảm thiểu bất kỳ sự gián đoạn nào đối với quy trình làm việc của người dùng.\n5. Thay thế bàn Mục tiêu: Khi tất cả các ETL và quy trình dữ liệu liên quan được chuyển đổi thành công để sử dụng các khả năng của Apache Iceberg và mọi thứ hoạt động chính xác với luồng đồng bộ hóa, đã đến lúc chuyển sang giai đoạn cuối cùng của quá trình di chuyển. Mục tiêu chính là duy trì tên bảng ban đầu, tránh sử dụng bất kỳ tiền tố nào như những tiền tố được sử dụng trong các bước di chuyển trung gian trước đó. Điều này giúp đảm bảo rằng cấu hình vẫn gọn gàng và không có phức tạp đặt tên không cần thiết.\nHình trước cho thấy việc thay thế bảng để hoàn tất quá trình di chuyển, trong đó Hive trên Amazon EMR được sử dụng để đăng ký các tệp Parquet dưới dạng bảng Iceberg trong khi vẫn giữ nguyên tên bảng ban đầu và tránh trùng lặp dữ liệu, giúp đảm bảo di chuyển liền mạch và gọn gàng.\nThực hiện:\nMột trong những thách thức là không thể đổi tên bảng trong AWS Glue, điều này ngăn cản việc sử dụng phương pháp đổi tên đơn giản cho các bảng luồng đồng bộ hóa hiện có. Ngoài ra, AWS Glue không hỗ trợ quy trình này tạo siêu dữ liệu Iceberg trên tệp dữ liệu hiện có trong khi vẫn giữ nguyên tên bảng ban đầu. Chiến lược để khắc phục hạn chế này là sử dụng metastore Hive trên cụm Amazon EMR. Bằng cách sử dụng Hive trên Amazon EMR, NI có thể tạo các bảng cuối cùng với tên ban đầu của chúng vì nó hoạt động trong một môi trường metastore riêng biệt, mang lại sự linh hoạt để xác định mọi lược đồ và tên bảng bắt buộc mà không bị can thiệp.Migrate\nQuy trình này được sử dụng để đăng ký một cách có phương pháp tất cả các tệp Parquet hiện có, do đó xây dựng tất cả siêu dữ liệu cần thiết trong Hive. Đây là một bước quan trọng, vì nó giúp đảm bảo rằng tất cả các tệp dữ liệu được lập danh mục và liên kết một cách thích hợp trong metastore.add_files\nHình trước cho thấy sự chuyển đổi của bảng sản xuất sang Iceberg bằng cách sử dụng thủ tục để đăng ký các tệp Parquet hiện có và tạo siêu dữ liệu Iceberg. Điều này giúp đảm bảo quá trình di chuyển suôn sẻ trong khi vẫn giữ nguyên dữ liệu gốc và tránh trùng lặp.add_files\nThiết lập này cho phép sử dụng các tệp Parquet hiện có mà không sao chép dữ liệu, do đó tiết kiệm tài nguyên. Mặc dù luồng đồng bộ hóa sử dụng các vùng lưu trữ riêng biệt cho kiến trúc cuối cùng, NI đã chọn duy trì các vùng lưu trữ ban đầu và dọn dẹp các tệp trung gian. Điều này dẫn đến cấu trúc thư mục khác trên Amazon S3. Dữ liệu lịch sử có các thư mục con cho mỗi phân vùng trong thư mục bảng gốc, trong khi dữ liệu Iceberg mới tổ chức các thư mục con trong thư mục dữ liệu. Sự khác biệt này có thể chấp nhận được để tránh trùng lặp dữ liệu và giữ nguyên các vùng lưu trữ Amazon S3 ban đầu.\nTóm tắt kỹ thuật Danh mục dữ liệu AWS Glue đóng vai trò là nguồn tin cậy chính cho các bản cập nhật lược đồ và bảng, với Amazon EventBridge ghi lại các sự kiện Danh mục dữ liệu để kích hoạt quy trình đồng bộ hóa. AWS Lambda phân tích siêu dữ liệu sự kiện và đồng bộ hóa lược đồ được quản lý, trong khi Apache Kafka đệm các sự kiện để xử lý theo thời gian thực. Apache Spark trên Amazon EMR xử lý chuyển đổi dữ liệu và cập nhật gia tăng, đồng thời Amazon DynamoDB duy trì trạng thái, bao gồm các điểm kiểm tra đồng bộ hóa và ánh xạ bảng. Cuối cùng, Snowflake sử dụng liền mạch các bảng Iceberg thông qua bí danh mà không làm gián đoạn quy trình làm việc hiện có.\nKết quả di chuyển Quá trình di chuyển đã được hoàn thành mà không có thời gian chết; Các hoạt động liên tục được duy trì trong suốt quá trình di chuyển, hỗ trợ hàng trăm đường ống và bảng điều khiển mà không bị gián đoạn. Quá trình di chuyển được thực hiện với tư duy tối ưu hóa chi phí với các bản cập nhật gia tăng và đồng bộ hóa cấp phân vùng giúp giảm thiểu việc sử dụng tài nguyên điện toán và lưu trữ. Cuối cùng, NI đã thiết lập một nền tảng hiện đại, trung lập với nhà cung cấp cho phép mở rộng nhu cầu phân tích và học máy đang phát triển của họ. Nó cho phép tích hợp liền mạch với nhiều công cụ điện toán và truy vấn, hỗ trợ tính linh hoạt và đổi mới hơn nữa.\nKết thúc Chuyển đổi trí tuệ tự nhiên sang Apache Iceberg là một bước quan trọng trong việc hiện đại hóa cơ sở hạ tầng dữ liệu của công ty. Bằng cách áp dụng chiến lược kết hợp và sử dụng sức mạnh của kiến trúc theo hướng sự kiện, NI đã giúp đảm bảo quá trình chuyển đổi liền mạch cân bằng giữa đổi mới với sự ổn định trong hoạt động. Hành trình nhấn mạnh tầm quan trọng của việc lập kế hoạch cẩn thận, hiểu hệ sinh thái dữ liệu và tập trung vào cách tiếp cận ưu tiên tổ chức.\nTrên hết, hoạt động kinh doanh được tập trung và tính liên tục ưu tiên trải nghiệm người dùng. Bằng cách đó, NI đã mở khóa tính linh hoạt và khả năng mở rộng của hồ dữ liệu của họ đồng thời giảm thiểu sự gián đoạn, cho phép các nhóm sử dụng khả năng phân tích tiên tiến, định vị công ty ở vị trí hàng đầu về quản lý dữ liệu hiện đại và sẵn sàng cho tương lai.\nNếu bạn đang cân nhắc di chuyển Apache Iceberg hoặc gặp phải những thách thức tương tự về cơ sở hạ tầng dữ liệu, chúng tôi khuyến khích bạn khám phá các khả năng. Nắm bắt các định dạng mở, sử dụng tự động hóa và thiết kế với nhu cầu riêng của tổ chức bạn. Hành trình có thể phức tạp, nhưng phần thưởng về khả năng mở rộng, tính linh hoạt và đổi mới rất xứng đáng với nỗ lực. Bạn có thể sử dụng hướng dẫn theo quy định của AWS để giúp tìm hiểu thêm về cách sử dụng Apache Iceberg tốt nhất cho tổ chức của bạn\nGiới thiệu về các tác giả\nẢnh đại diện Giới thiệu về các tác giả Yonatan Dolan là Chuyên gia phân tích chính tại Amazon Web Services. Yonatan là một nhà truyền giáo Apache Iceberg. Haya Stern là Giám đốc Cấp cao về Dữ liệu tại Natural Intelligence. Cô lãnh đạo việc phát triển nền tảng dữ liệu quy mô lớn của NI, tập trung vào việc cho phép phân tích, hợp lý hóa quy trình làm việc dữ liệu và cải thiện hiệu quả phát triển. Trong năm qua, cô đã dẫn dắt việc di chuyển thành công từ kiến trúc dữ liệu trước đó sang một ngôi nhà hồ hiện đại dựa trên Apache Iceberg và Snowflake. Zion Rubin là Kiến trúc sư dữ liệu tại Natural Intelligence với mười năm kinh nghiệm kiến trúc các nền tảng dữ liệu lớn quy mô lớn, hiện tập trung vào việc phát triển các hệ thống tác nhân thông minh biến dữ liệu phức tạp thành thông tin chi tiết về kinh doanh theo thời gian thực. Michał Urbanowicz là Kỹ sư dữ liệu đám mây tại Natural Intelligence với chuyên môn trong việc di chuyển kho dữ liệu và triển khai các quy trình lưu giữ, dọn dẹp và giám sát mạnh mẽ để đảm bảo khả năng mở rộng và độ tin cậy. Ông cũng phát triển các tính năng tự động hóa giúp hợp lý hóa và hỗ trợ các hoạt động quản lý chiến dịch trong môi trường dựa trên đám mây. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Xây dựng website tĩnh với S3 và kết nối database RDS\nTuần 3: Tối ưu hiệu suất với CloudFront, DynamoDB và ElastiCache\nTuần 4: Migration và Disaster Recovery với DMS và EDR\nTuần 5: Infrastructure as Code với CloudFormation, CDK và Systems Manager\nTuần 6: Làm công việc về Bảo mật và Quản lý chi phí với IAM Policy, KMS, Secrets Manager, Billing Dashboard và AWS Budgets\nTuần 7: Nâng cao độ khả năng mở rộng hệ thống với Auto Scaling, Load Balancer, SQS/SNS, và VPC Flow Logs\nTuần 8: Ôn tập AWS Well-Architected Framework và củng cố kiến thức các dịch vụ trọng tâm\nTuần 9: Thực hành các dịch vụ Data \u0026amp; Analytics: Data Lake với S3, Glue, Athena và QuickSight\nTuần 10: Thực hành các dịch vụ AI/ML: SageMaker, Rekognition, Comprehend và Kendra\nTuần 11: Viết proposal và hoàn thiện làm dự án cuối kỳ\nTuần 12: Dự án cuối kỳ - Tổng kết kiến thức và xây dựng dự án AWS hoàn chỉnh\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 1 – AWS Journey 1. Mục tiêu hàng tuần Mục tiêu chính của Tuần 1 là thiết lập môi trường nền tảng cho hành trình AWS và hiểu các nguyên tắc vận hành cốt lõi. Các mục tiêu cụ thể bao gồm:\nOnboarding (Nhập môn): Làm quen với quy trình thực tập FCJ, các kênh liên lạc và nội quy. Thiết lập tài khoản: Hoàn tất đăng ký AWS Free Tier, cấu hình AWS CLI, và kích hoạt các chuẩn bảo mật cơ bản (MFA, IAM). Dịch vụ cốt lõi: Có cái nhìn tổng quan về hệ sinh thái AWS (Tính toán, Lưu trữ, Mạng, Cơ sở dữ liệu, Bảo mật). Thực hành: Sử dụng thành thạo AWS Management Console \u0026amp; AWS CLI v2. Cơ sở hạ tầng: Triển khai và vận hành một instance EC2 t2.micro và thực hiện các thao tác EBS cơ bản. Kiểm soát chi phí: Thiết lập AWS Budgets để giám sát chi tiêu. 2. Tóm tắt công việc chi tiết 🗂 Kế hoạch thực hiện so với Thực tế Hạng mục Kế hoạch Thực tế Trạng thái Onboarding \u0026amp; Nội quy Giới thiệu, nắm bắt kênh liên lạc Đã được giới thiệu, ghi chú chuẩn báo cáo ✅ Hoàn thành Tổng quan AWS Hệ thống hóa nhóm dịch vụ + Mindmap Hoàn tất, đã ghi chú theo phân loại ✅ Hoàn thành Free Tier \u0026amp; Bảo mật Tạo tài khoản, bật MFA, tạo IAM user Đã bật MFA; tạo user + nhóm Viewer ✅ Hoàn thành AWS CLI Cài đặt CLI, cấu hình profile Đã set profile acj-student, test sts OK ✅ Hoàn thành EC2/EBS/SSH Tạo EC2, SSH, gắn EBS EC2 t2.micro + EBS 8GB gp3, SSH thành công ✅ Hoàn thành Quản lý chi phí Đặt ngân sách $5/tháng Đã nhận email cảnh báo thử nghiệm ✅ Hoàn thành 📅 Nhật ký hoạt động theo ngày Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo Thứ Hai Onboarding: Định hướng FCJ, đọc nội quy, học chuẩn báo cáo 08/09 08/09 AWS Journey Thứ Ba Nghiên cứu: Khám phá hệ sinh thái AWS (Compute/Storage/Networking/DB/Security), tạo mindmap 09/09 09/09 AWS Journey Thứ Tư Thiết lập tài khoản: Tạo AWS Free Tier, bật MFA cho root, tạo IAM user + nhóm Viewer 10/09 10/09 AWS Journey Thứ Năm Cài đặt CLI: Cài AWS CLI v2 (Windows), chạy aws configure (profile acj-student), kiểm tra danh tính sts 11/09 11/09 AWS Journey Thứ Sáu Lý thuyết: Học về EC2 (loại instance, AMI, EBS, SG, Elastic IP) + checklist Free Tier 12/09 12/09 AWS Journey Thứ Bảy Thực hành: Tạo EC2 t2.micro (AL2023), tạo/dùng key pair (.pem), SSH; gắn EBS 8GB, định dạng \u0026amp; mount 13/09 13/09 AWS Journey 3. Kết quả \u0026amp; Minh chứng 3.1 Tài nguyên đã tạo IAM: 01 User làm việc hàng ngày (Nhóm: Viewer), đã bật MFA cho tài khoản root. EC2: t2.micro (Free Tier), AMI: Amazon Linux 2023. Security Group: Quy tắc Inbound mở cổng 22/tcp chỉ giới hạn cho My IP. EBS: Volume 8GB gp3, đã định dạng (xfs) và mount vào thư mục /data. Budgets: Ngân sách hàng tháng đặt mức $5 USD với cảnh báo qua email. CLI Region: Mặc định là ap-southeast-1 (Singapore). 3.2 Các lệnh CLI đã thực thi aws sts get-caller-identity --profile acj-student aws ec2 describe-regions --profile acj-student --output table aws ec2 describe-instances --profile acj-student --region ap-southeast-1 aws ec2 create-key-pair --key-name fcj-key --query \u0026#34;KeyMaterial\u0026#34; --output text \u0026gt; fcj-key.pem "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 2 – AWS Journey 1. Mục tiêu hàng tuần Trong Tuần 2, mục tiêu chính là đạt được kinh nghiệm thực tế nền tảng với các dịch vụ cơ sở hạ tầng cốt lõi của AWS, bao gồm:\nAmazon S3 – Lưu trữ trang web tĩnh và quản lý quyền truy cập bucket. Amazon RDS (MySQL) – Cấp phát cơ sở dữ liệu quan hệ được quản lý và cấu hình kết nối. Amazon EC2 – Sử dụng EC2 instance như một máy chủ trung gian (bastion host) bảo mật để truy cập RDS. Amazon Route53 – Quản lý tên miền và ánh xạ bản ghi DNS tới các dịch vụ AWS. Tuần này tập trung vào việc xây dựng các thành phần kiến trúc đám mây cơ bản, đóng vai trò là tiền đề cho các nhiệm vụ của Tuần 3 liên quan đến CloudFront, DynamoDB và ElastiCache.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Tạo S3 bucket cho nội dung web tĩnh\n- Tải lên các tệp demo HTML/CSS ban đầu 15/09/2025 15/09/2025 AWS Journey Thứ Ba - Bật tính năng Static Website Hosting trên S3\n- Cấu hình Bucket Policy cho phép quyền đọc công khai (public read)\n- Kiểm tra truy cập website qua endpoint S3 16/09/2025 16/09/2025 AWS Journey Thứ Tư - Tạo RDS MySQL instance (Gói Free Tier)\n- Cấu hình VPC Security Groups cho lưu lượng truy cập vào\n- Ghi lại endpoint DB \u0026amp; thông tin đăng nhập 17/09/2025 17/09/2025 AWS Journey Thứ Năm - Khởi chạy EC2 instance và cài đặt MySQL client\n- Kết nối từ EC2 → RDS bằng dòng lệnh\n- Thực thi các truy vấn thử nghiệm và tạo bảng mẫu 18/09/2025 18/09/2025 AWS Journey Thứ Sáu - Tìm hiểu chức năng Route53\n- Tạo Hosted Zone và các bản ghi DNS (A/CNAME)\n- Cấu hình định tuyến từ tên miền tùy chỉnh → trang web tĩnh S3\n- Xác thực truy cập website bằng tên miền 19/09/2025 19/09/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 AWS S3 – Thiết lập Website tĩnh Tạo S3 bucket mới tuân theo quy ước đặt tên và vị trí vùng (region). Tải lên tài nguyên tĩnh (HTML/CSS/Hình ảnh). Bật tính năng Static Website Hosting. Cấu hình index.html và error.html. Thêm Bucket Policy (quyền public-read) để phục vụ nội dung toàn cầu. Xác minh khả năng truy cập qua endpoint của website: http://\u0026lt;bucket-name\u0026gt;.s3-website-\u0026lt;region\u0026gt;.amazonaws.com 3.2 Amazon RDS – Cấp phát Cơ sở dữ liệu Khởi chạy instance RDS MySQL 8.0 thuộc gói Free Tier. Áp dụng các quy tắc Security Group bảo mật (EC2 → RDS, cổng 3306). Lưu trữ endpoint được tạo để kết nối sau này. Đảm bảo DB subnet group và cấu hình VPC hợp lệ cho truy cập riêng tư. 3.3 Amazon EC2 – Kết nối DB bảo mật Tạo một instance EC2 t2.micro trong cùng VPC với RDS instance. Cài đặt MySQL Client: sudo yum install mysql -y Kết nối thành công đến RDS: mysql -h \u0026lt;rds-endpoint\u0026gt; -u admin -p Tạo cơ sở dữ liệu mẫu và bảng để kiểm tra. 3.4 Amazon Route53 – Cấu hình DNS Thiết lập một Hosted Zone mới. Thêm các bản ghi DNS: A Record → Trang web tĩnh S3. CNAME Record cho các bí danh thử nghiệm. Chờ DNS lan truyền (thường từ 1–5 phút). Truy cập thành công trang web tĩnh bằng tên miền tùy chỉnh. 4. Thành tựu Đến cuối Tuần 2, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Hoàn thành một trang web tĩnh được lưu trữ trên S3 hoạt động hoàn chỉnh. Cho phép truy cập qua cả endpoint S3 và tên miền Route53. Triển khai và kết nối thành công cơ sở dữ liệu RDS MySQL. Xác minh giao tiếp bảo mật giữa EC2 ↔ RDS. ✔ Phát triển kỹ năng Thể hiện sự hiểu biết về: IAM roles \u0026amp; quyền hạn. Kiểm soát truy cập S3. Mạng VPC \u0026amp; Security Groups. Các khái niệm định tuyến DNS. Có được kinh nghiệm nền tảng với các dịch vụ cốt lõi của AWS. Củng cố hiểu biết về luồng ứng dụng đám mây đầu cuối (end-to-end). Xây dựng sự tự tin khi làm việc với các thao tác dòng lệnh (CLI). Cải thiện kỹ năng khắc phục sự cố (lan truyền DNS, cấu hình SG và chính sách truy cập công khai). 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: S3 Public Access Block (Chặn truy cập công khai)\nVấn đề: Website không thể truy cập do cài đặt chặn truy cập công khai mặc định của S3. Giải pháp: Tắt cài đặt “Block Public Access” và thêm bucket policy chính xác. Thách thức 2: Lỗi kết nối EC2 -\u0026gt; RDS (Timeout)\nVấn đề: Security Group không cho phép lưu lượng MySQL đi vào. Giải pháp: Sửa đổi Security Group của RDS để chấp nhận lưu lượng cụ thể từ Security Group của EC2 trên cổng 3306. Thách thức 3: DNS không phân giải ngay lập tức\nVấn đề: Tên miền mất thời gian để cập nhật trong Route53. Giải pháp: Chờ hết thời gian TTL và kiểm tra lại bằng lệnh dig / nslookup. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 3 – AWS Journey 1. Mục tiêu hàng tuần Trong Tuần 3, mục tiêu chính là tối ưu hóa hiệu suất ứng dụng và mở rộng kỹ năng quản lý dữ liệu ngoài cơ sở dữ liệu quan hệ. Các mục tiêu cụ thể bao gồm:\nAmazon CloudFront – Hiểu về Mạng phân phối nội dung (CDN) và tối ưu hóa việc phân phối trang web tĩnh. Amazon DynamoDB – Có kinh nghiệm thực tế với mô hình hóa và vận hành cơ sở dữ liệu NoSQL. Amazon ElastiCache (Redis) – Triển khai bộ nhớ đệm (caching) để cải thiện tốc độ đọc dữ liệu. Tích hợp AWS CLI – Tương tác nâng cao với các dịch vụ AWS bằng các tập lệnh dòng lệnh. Tuần này tập trung vào việc chuyển đổi từ kiến trúc cơ bản sang mô hình hiệu suất cao, có khả năng mở rộng bằng cách sử dụng các lớp caching và dịch vụ NoSQL được quản lý.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Giới thiệu khái niệm CDN và lợi ích của CloudFront\n- Tạo CloudFront Distribution để phân phối nội dung web từ S3 22/09/2025 22/09/2025 AWS Journey Thứ Ba - Cấu hình hành vi (behaviors) và chính sách cache cho CloudFront\n- Kiểm tra truy cập web qua URL CloudFront\n- Thực hiện Invalidation (làm mới cache) để cập nhật nội dung mới 23/09/2025 23/09/2025 AWS Journey Thứ Tư - Giới thiệu DynamoDB (Kiến trúc NoSQL)\n- Tạo các bảng DynamoDB (Users, Products)\n- Thực hành các thao tác CRUD trên Console 24/09/2025 24/09/2025 AWS Journey Thứ Năm - Kết nối và truy vấn DynamoDB bằng AWS CLI\n- Viết các script nhỏ để thêm (put-item) và đọc dữ liệu 25/09/2025 25/09/2025 AWS Journey Thứ Sáu - Tìm hiểu về ElastiCache (Redis \u0026amp; Memcached)\n- Khởi tạo cụm Redis cơ bản\n- Kiểm tra kết nối từ EC2 để lưu/đọc dữ liệu cache 26/09/2025 26/09/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 Amazon CloudFront – Tích hợp CDN Tạo distribution trỏ đến S3 bucket đã tạo trong Tuần 2. Cấu hình Origin Access Control (OAC) để chỉ cho phép truy cập S3 thông qua CloudFront. Bật HTTPS sử dụng chứng chỉ mặc định của CloudFront. Kiểm tra sự cải thiện hiệu suất (giảm độ trễ) so với truy cập trực tiếp S3. Thực hiện invalidation thủ công cho tệp index.html: aws cloudfront create-invalidation --distribution-id \u0026lt;ID\u0026gt; --paths \u0026#34;/*\u0026#34; 3.2 Amazon DynamoDB – Triển khai NoSQL Tạo bảng Users với UserId làm Khóa phân vùng (Partition Key). Thực hiện các thao tác CRUD (Tạo, Đọc, Cập nhật, Xóa) thông qua Giao diện quản lý (Console). Tương tác qua AWS CLI để chèn dữ liệu: aws dynamodb put-item \\ --table-name Users \\ --item \u0026#39;{\u0026#34;UserId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;u-101\u0026#34;}, \u0026#34;Name\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Alice\u0026#34;}, \u0026#34;Role\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Admin\u0026#34;}}\u0026#39; Xác thực dữ liệu đã chèn bằng lệnh scan. 3.3 Amazon ElastiCache – Thiết lập Redis Khởi chạy cụm ElastiCache for Redis (cache.t2.micro hoặc t3.micro). Cấu hình Security Groups để cho phép lưu lượng vào cổng 6379 từ EC2 instance. Kết nối từ EC2 bằng redis-cli (cài đặt qua amazon-linux-extras hoặc yum). Kiểm tra logic lưu bộ nhớ đệm: set mykey \u0026#34;Hello AWS\u0026#34; get mykey # Kết quả: \u0026#34;Hello AWS\u0026#34; 4. Thành tựu Đến cuối Tuần 3, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Tăng tốc thành công trang web tĩnh S3 trên phạm vi toàn cầu bằng CloudFront. Thể hiện kiến thức làm việc với cấu trúc dữ liệu NoSQL. Thiết lập cụm Redis cache hoạt động tốt, có thể truy cập từ tài nguyên VPC riêng tư. Tích hợp AWS CLI để quản lý cơ sở dữ liệu, vượt ra khỏi các thao tác chỉ dùng Console. ✔ Phát triển kỹ năng Hiểu rõ vai trò của các vị trí biên (edge locations) và chiến lược caching. Nắm vững sự khác biệt giữa mô hình Quan hệ (RDS) và NoSQL (DynamoDB). Học cách thực hiện Cache Invalidation khi cập nhật nội dung tĩnh. Có kinh nghiệm trong việc bảo mật các lớp cache nội bộ (ElastiCache) thông qua Security Groups. 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Nội dung CloudFront không cập nhật\nVấn đề: Các cập nhật cho index.html trên S3 không phản ánh ngay lập tức trên trang web. Giải pháp: Tìm hiểu về TTL (Time To Live) và thực hiện CloudFront Invalidation để buộc làm mới dữ liệu. Thách thức 2: Cú pháp phức tạp của DynamoDB CLI\nVấn đề: Gặp khó khăn khi định dạng JSON chính xác cho các lệnh CLI. Giải pháp: Sử dụng công cụ tạo JSON và tham khảo tài liệu AWS CLI để biết cú pháp AttributeValue chính xác (S, N, v.v.). Thách thức 3: Kết nối Redis từ máy cá nhân\nVấn đề: Cố gắng kết nối với ElastiCache từ bên ngoài VPC (thất bại). Giải pháp: Hiểu rằng ElastiCache chỉ dành cho mạng nội bộ VPC; sử dụng EC2 bastion host đã thiết lập ở Tuần 2 làm máy trung gian (jump box). "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 4 – AWS Journey 1. Mục tiêu hàng tuần Trong Tuần 4, trọng tâm chính chuyển sang các Chiến lược di chuyển (Migration) và Đảm bảo tính liên tục trong kinh doanh (Business Continuity). Mục tiêu là hiểu cách chuyển khối lượng công việc từ on-premise (tại chỗ) lên đám mây và đảm bảo hệ thống có khả năng phục hồi trước các sự cố. Các mục tiêu chính bao gồm:\nQuy trình Migration – Hiểu về \u0026ldquo;6 Rs\u0026rdquo; trong di chuyển (Rehost, Replatform, Refactor, v.v.). AWS Database Migration Service (DMS) – Di chuyển dữ liệu từ cơ sở dữ liệu nguồn sang Amazon RDS với thời gian ngừng hoạt động tối thiểu. Elastic Disaster Recovery (EDR) – Triển khai sao chép và chiến lược phục hồi để giảm thiểu mất mát dữ liệu. Lập kế hoạch Khôi phục thảm họa (DR) – Xác định RTO (Thời gian khôi phục mục tiêu) và RPO (Điểm khôi phục mục tiêu). Tuần này thiết lập các kỹ năng quan trọng cần thiết cho độ tin cậy và hiện đại hóa cơ sở hạ tầng cấp doanh nghiệp.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Tìm hiểu các khái niệm Migration (Lift \u0026amp; Shift, Replatform, Refactor)\n- Giới thiệu về AWS Database Migration Service (DMS) 29/09/2025 29/09/2025 AWS Journey Thứ Ba - Thực hành tạo Replication Instance trong DMS\n- Cấu hình nguồn dữ liệu (giả lập on-premise) và đích (RDS)\n- Thực hiện di chuyển dữ liệu thử nghiệm 30/09/2025 30/09/2025 AWS Journey Thứ Tư - Giới thiệu về Elastic Disaster Recovery (EDR)\n- Tìm hiểu cách thiết lập máy chủ sao chép và instance khôi phục 01/10/2025 01/10/2025 AWS Journey Thứ Năm - Thực hành mô phỏng sự cố: tắt EC2 chính và khởi chạy instance khôi phục từ EDR\n- Đánh giá thời gian khôi phục (RTO/RPO) 02/10/2025 02/10/2025 AWS Journey Thứ Sáu - Tạo kế hoạch DR cơ bản (sao lưu, khôi phục, chuyển đổi dự phòng)\n- Viết tài liệu tổng hợp quy trình Migration + DR 03/10/2025 03/10/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 AWS Database Migration Service (DMS) Replication Instance: Cấp phát một instance dms.t2.micro trong VPC để xử lý tác vụ di chuyển. Cấu hình Endpoints: Source (Nguồn): Cấu hình cơ sở dữ liệu MySQL trên EC2 (mô phỏng máy chủ tại chỗ) với quyền truy cập phù hợp. Target (Đích): Kết nối với RDS MySQL instance đã tạo ở Tuần 2. Tác vụ Migration: Tạo tác vụ \u0026ldquo;Full Load\u0026rdquo; (Tải toàn bộ) để di chuyển các bảng hiện có. Quy tắc ánh xạ: Cấu hình quy tắc chọn lược đồ (schema) để bao gồm các bảng cụ thể (ví dụ: Users, Products). 3.2 Thiết lập Elastic Disaster Recovery (EDR) Khởi tạo dịch vụ EDR trong Region AWS cụ thể. Cài đặt Agent: Tải xuống và cài đặt AWS Replication Agent trên EC2 instance nguồn (Linux). Staging Area: Xác minh rằng máy chủ sao chép đã tự động khởi chạy trong subnet staging. Sao chép dữ liệu: Theo dõi tiến trình đồng bộ hóa ban đầu cho đến khi trạng thái đạt \u0026ldquo;Healthy\u0026rdquo; và \u0026ldquo;Data replicated\u0026rdquo;. 3.3 Mô phỏng chuyển đổi dự phòng (Failover Drill) Kịch bản: Mô phỏng sự cố nghiêm trọng bằng cách dừng (Stop) instance EC2 nguồn. Hành động khôi phục: Khởi tạo \u0026ldquo;Recovery Drill\u0026rdquo; trong giao diện điều khiển EDR. Cài đặt khởi chạy: Cấu hình Launch Template (loại instance, security groups) cho instance khôi phục. Xác thực: SSH thành công vào Recovery Instance đã khởi chạy và xác minh tính toàn vẹn của dữ liệu ứng dụng. 3.4 Lập kế hoạch \u0026amp; Tài liệu DR Soạn thảo kế hoạch DR cơ bản phác thảo: Chiến lược sao lưu: Snapshots tự động so với Sao chép liên tục. Các bước Failover: Trình tự các hành động để chuyển sang trang web khôi phục. Phân tích RTO/RPO: Đo lường thời gian khôi phục (RTO) và lượng dữ liệu có thể bị trễ (RPO). 4. Thành tựu Đến cuối Tuần 4, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Di chuyển dữ liệu thành công giữa hai điểm cuối cơ sở dữ liệu bằng AWS DMS. Cấu hình sao chép liên tục ở cấp độ khối (block-level) bằng Elastic Disaster Recovery. Thực hiện thành công cuộc diễn tập failover, đưa máy chủ khôi phục hoạt động trong vòng vài phút. Xác minh tính nhất quán dữ liệu giữa hệ thống Nguồn và Đích. ✔ Phát triển kỹ năng Hiểu rõ trọn vẹn Vòng đời di chuyển (Migration lifecycle) (Đánh giá → Huy động → Di chuyển \u0026amp; Hiện đại hóa). Có kinh nghiệm thực tế với các khái niệm mạng Hybrid Cloud (Nguồn → AWS). Hiểu sâu hơn về Lập kế hoạch kinh doanh liên tục (BCP). Học cách phân biệt giữa các chiến lược Sao lưu (Backup) và giải pháp Khôi phục thảm họa (Disaster Recovery). 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Lỗi kết nối DMS\nVấn đề: Replication Instance không thể kết nối với cơ sở dữ liệu EC2 nguồn. Giải pháp: Cập nhật Security Group của nguồn để cho phép lưu lượng vào cổng 3306 cụ thể từ Private IP của DMS Replication Instance. Thách thức 2: Lỗi cài đặt EDR Agent\nVấn đề: Agent sao chép không cài đặt được do thiếu quyền IAM. Giải pháp: Tạo một IAM user với các access keys lập trình cụ thể cần thiết cho AWS Replication Agent và chạy lại trình cài đặt. Thách thức 3: RTO cao trong quá trình diễn tập\nVấn đề: Instance khôi phục mất nhiều thời gian hơn dự kiến để sẵn sàng. Giải pháp: Tối ưu hóa Launch Template để sử dụng AMI phù hợp hoặc loại instance tốt hơn để tăng tốc quá trình khởi động. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 5 – AWS Journey 1. Mục tiêu hàng tuần Trong Tuần 5, trọng tâm chuyển từ các thao tác thủ công (\u0026ldquo;ClickOps\u0026rdquo;) sang Cơ sở hạ tầng dưới dạng mã (IaC) và Vận hành hệ thống. Mục tiêu là tự động hóa việc cấp phát và quản lý tài nguyên để đảm bảo tính nhất quán và tốc độ. Các mục tiêu chính bao gồm:\nCơ sở hạ tầng dưới dạng mã (IaC) – Tìm hiểu AWS CloudFormation và AWS Cloud Development Kit (CDK). Tự động hóa – Viết các mẫu (templates) và mã để triển khai S3 buckets và EC2 instances bằng lập trình. AWS Systems Manager (SSM) – Tập trung hóa dữ liệu vận hành và quản lý máy chủ mà không cần khóa SSH. Tối ưu vận hành – Triển khai các quy trình tự động khởi động/dừng máy chủ để tiết kiệm chi phí. Tuần này đánh dấu sự chuyển đổi sang các thực hành DevOps, chuẩn bị cho việc quản lý cơ sở hạ tầng có khả năng mở rộng.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Giới thiệu về khái niệm IaC và lợi ích so với triển khai thủ công\n- Làm quen với AWS CloudFormation: template, stack, parameter 06/10/2025 06/10/2025 AWS Journey Thứ Ba - Viết CloudFormation template để triển khai S3 bucket và EC2 instance\n- Tạo, cập nhật và xóa stack thông qua AWS Console 07/10/2025 07/10/2025 AWS Journey Thứ Tư - Giới thiệu về AWS CDK (Cloud Development Kit)\n- Cài đặt AWS CDK, tạo dự án CDK bằng Python hoặc TypeScript\n- Viết mã CDK để triển khai EC2 instance 08/10/2025 08/10/2025 AWS Journey Thứ Năm - Giới thiệu về AWS Systems Manager (SSM) và các tính năng chính\n- Tạo Parameter Store để lưu trữ các biến cấu hình 09/10/2025 09/10/2025 AWS Journey Thứ Sáu - Thực hành tạo Automation Document trong SSM để tự động Start/Stop EC2\n- Test Session Manager (truy cập EC2 không cần khóa SSH)\n- Tổng kết tuần: Demo IaC + SSM 10/10/2025 10/10/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 AWS CloudFormation Thiết kế Template: Tạo tệp YAML định nghĩa AWS::S3::Bucket và AWS::EC2::Instance. Parameters (Tham số): Sử dụng Parameters để cho phép nhập InstanceType (ví dụ: t2.micro) tại thời điểm triển khai. Thao tác với Stack: Create Stack: Tải template lên CloudFormation Designer. Update Stack: Sửa đổi template (thêm tags) và áp dụng changeset. Drift Detection: Kiểm tra xem tài nguyên có bị thay đổi thủ công bên ngoài stack hay không. 3.2 AWS CDK (Cloud Development Kit) Cài đặt: Cài đặt Node.js và CDK CLI (npm install -g aws-cdk). Khởi tạo: Tạo dự án mới: cdk init app --language python. Viết mã: Định nghĩa tài nguyên sử dụng các cấu trúc cấp cao (L2 constructs) bằng Python. Triển khai: cdk synth: Tạo ra template CloudFormation từ mã nguồn. cdk deploy: Cấp phát tài nguyên vào tài khoản AWS. 3.3 AWS Systems Manager (SSM) Parameter Store: Tạo các tham số phân cấp (ví dụ: /dev/db/password) dạng SecureString để lưu cấu hình nhạy cảm. Session Manager: Gắn IAM role AmazonSSMManagedInstanceCore vào EC2 instance. Kết nối thành công vào shell của instance thông qua AWS Console (trình duyệt) mà không cần mở cổng 22 (SSH). Automation: Thực thi một SSM Document (AWS-StopEC2Instance) để kiểm tra các tác vụ vận hành tự động. 4. Thành tựu Đến cuối Tuần 5, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Thay thế thành công việc tạo tài nguyên thủ công bằng các CloudFormation templates có thể tái sử dụng. Triển khai một stack cơ sở hạ tầng hoạt động tốt bằng mã lệnh (CDK). Loại bỏ nhu cầu quản lý khóa SSH nhờ sử dụng SSM Session Manager. Tập trung hóa việc quản lý cấu hình bằng SSM Parameter Store. ✔ Phát triển kỹ năng Hiểu sự khác biệt giữa các phương pháp IaC Declarative (Khai báo - CloudFormation) và Imperative (Mệnh lệnh - CDK). Học được tầm quan trọng của tính Idempotency (Tính bất biến/nhất quán) trong triển khai cơ sở hạ tầng. Có kinh nghiệm quản lý dựa trên Agent (SSM Agent). Cải thiện tư thế bảo mật bằng cách loại bỏ nhu cầu truy cập SSH công khai. 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Lỗi thụt lề (Indentation) trong CloudFormation YAML\nVấn đề: Việc tạo Stack thất bại do lỗi phân tích cú pháp trong tệp YAML. Giải pháp: Sử dụng YAML Linter và tiện ích mở rộng VS Code \u0026ldquo;CloudFormation Linter\u0026rdquo; để xác thực cú pháp trước khi tải lên. Thách thức 2: CDK Bootstrapping\nVấn đề: Lệnh cdk deploy thất bại với lỗi thiếu toolkit stack. Giải pháp: Hiểu rằng môi trường phải được bootstrap một lần cho mỗi region bằng lệnh cdk bootstrap aws://\u0026lt;account-id\u0026gt;/\u0026lt;region\u0026gt;. Thách thức 3: SSM Agent không kết nối\nVấn đề: EC2 instance không xuất hiện trong Systems Manager Fleet Manager. Giải pháp: Phát hiện ra EC2 instance thiếu IAM Role cần thiết (AmazonSSMManagedInstanceCore). Đã gắn role và khởi động lại instance. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 6 – AWS Journey 1. Mục tiêu hàng tuần Trong Tuần 6, trọng tâm chuyển sang các trụ cột quan trọng của khung kiến trúc Well-Architected: Bảo mật (Security) và Tối ưu hóa chi phí (Cost Optimization). Các mục tiêu chính bao gồm:\nQuản lý danh tính \u0026amp; truy cập (IAM) – Nắm vững cấu trúc chính sách nâng cao để thực thi Nguyên tắc đặc quyền tối thiểu (Least Privilege). Bảo mật dữ liệu – Triển khai mã hóa bằng AWS KMS và quản lý thông tin xác thực với Secrets Manager. Quản lý chi phí – Phân tích mô hình chi tiêu thông qua Cost Explorer và thiết lập cảnh báo tự động với AWS Budgets. Tuần này đảm bảo rằng cơ sở hạ tầng được xây dựng trong các tuần trước không chỉ hoạt động tốt mà còn an toàn và hiệu quả về mặt tài chính.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Ôn tập kiến thức IAM cơ bản\n- Học IAM Policy nâng cao (Cấu trúc JSON, Điều kiện)\n- Tạo chính sách tùy chỉnh và gắn cho users/groups 13/10/2025 13/10/2025 AWS Journey Thứ Ba - Giới thiệu về AWS Key Management Service (KMS)\n- Tạo Customer Managed Key (CMK)\n- Áp dụng KMS để mã hóa S3 bucket hoặc EBS volume 14/10/2025 14/10/2025 AWS Journey Thứ Tư - Làm quen với AWS Secrets Manager\n- Tạo secret để lưu thông tin kết nối Database\n- Viết script Lambda nhỏ để đọc secret từ Secrets Manager 15/10/2025 15/10/2025 AWS Journey Thứ Năm - Khám phá AWS Billing Dashboard và Cost Explorer\n- Xem chi phí theo dịch vụ, khu vực và loại sử dụng\n- Thiết lập Cost Anomaly Detection (Phát hiện bất thường) 16/10/2025 16/10/2025 AWS Journey Thứ Sáu - Tạo AWS Budget và cấu hình cảnh báo qua email\n- Viết báo cáo tổng hợp chi phí tuần với đề xuất tối ưu hóa (tắt EC2, dọn dẹp EBS)\n- Tổng kết kiến thức Tuần 6 17/10/2025 17/10/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 Chính sách IAM Nâng cao Phân tích cấu trúc JSON: Version, Statement, Effect, Action, Resource. Tạo Chính sách dựa trên điều kiện (Condition) để hạn chế truy cập theo IP nguồn hoặc tags: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-secure-bucket/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;IpAddress\u0026#34;: {\u0026#34;aws:SourceIp\u0026#34;: \u0026#34;203.0.113.0/24\u0026#34;} } } Gắn các chính sách trực tiếp (inline) vào các IAM Group cụ thể để thực thi phân chia nhiệm vụ. 3.2 Mã hóa dữ liệu với AWS KMS Tạo khóa Customer Managed Key (CMK) (Đối xứng). Cấu hình Key Policy để xác định Quản trị viên khóa và Người dùng khóa. Bật mã hóa mặc định trên một S3 bucket sử dụng CMK mới tạo. Thử nghiệm mã hóa thủ công qua CLI: aws kms encrypt --key-id \u0026lt;key-id\u0026gt; --plaintext fileb://data.txt --output text --query CiphertextBlob 3.3 Tích hợp AWS Secrets Manager Lưu trữ thông tin đăng nhập RDS (username/password) an toàn trong Secrets Manager. Cấu hình cài đặt tự động xoay vòng (automatic rotation) (tìm hiểu khái niệm). Phát triển script Python (Boto3) cho Lambda để lấy secret bằng lập trình, tránh việc hardcode thông tin xác thực trong mã nguồn. 3.4 Quản lý \u0026amp; Tối ưu hóa chi phí Cost Explorer: Kích hoạt các thẻ (tags) (ví dụ: Project: WebApp) để lọc chi phí theo từng khối lượng công việc cụ thể. AWS Budgets: Thiết lập ngân sách hàng tháng là $10.00 với cảnh báo kích hoạt khi sử dụng đạt 80% ($8.00). Anomaly Detection: Bật phát hiện bất thường chi phí AWS để nhận diện các đợt tăng đột biến trong việc sử dụng dịch vụ (ví dụ: vòng lặp Lambda không mong muốn). 4. Thành tựu Đến cuối Tuần 6, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Thành thạo việc tạo và áp dụng các IAM Policy chi tiết để kiểm soát chặt chẽ quyền truy cập tài nguyên. Triển khai thành công mã hóa dữ liệu khi nghỉ (encryption at rest) cho S3 và EBS bằng KMS. Thay thế thông tin đăng nhập database hardcode bằng việc truy xuất động từ Secrets Manager. Thiết lập khung quản trị chi phí sử dụng Budgets và Alerts. ✔ Phát triển kỹ năng Hiểu sâu hơn về Mô hình trách nhiệm chia sẻ liên quan đến bảo mật. Học cách cân bằng giữa sự nghiêm ngặt về bảo mật và khả năng vận hành dễ dàng. Có nhận thức về \u0026ldquo;FinOps\u0026rdquo;: cách phân tích chi phí, đề xuất các biện pháp tối ưu hóa (ví dụ: dừng EC2 nhàn rỗi, xóa EBS không gắn kết) và duy trì hiệu quả. 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Bị từ chối truy cập do KMS Key Policy\nVấn đề: Một IAM user có quyền Admin nhưng không thể giải mã file. Giải pháp: Hiểu rằng KMS Key Policies tách biệt với IAM policies. Đã thêm ARN của user vào phần \u0026ldquo;Key Users\u0026rdquo; trong chính sách của KMS. Thách thức 2: Chi phí/Độ trễ của Secrets Manager\nVấn đề: Việc gọi Secrets Manager quá thường xuyên làm tăng chi phí và độ trễ. Giải pháp: Triển khai cơ chế caching trong mã nguồn Lambda để lưu secret tạm thời trong ngữ cảnh thực thi (execution context). Thách thức 3: Đọc hiểu dữ liệu Cost Explorer\nVấn đề: Chi phí cho mục \u0026ldquo;EC2-Other\u0026rdquo; cao và không rõ ràng. Giải pháp: Phân tích sâu hơn theo \u0026ldquo;Usage Type\u0026rdquo; (Loại sử dụng) để xác định chi phí đến từ truyền tải dữ liệu qua NAT Gateway, dẫn đến việc xem xét lại kiến trúc. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 7 – AWS Journey 1. Mục tiêu hàng tuần Trong Tuần 7, trọng tâm là xây dựng Tính sẵn sàng cao (High Availability - HA) và Khả năng mở rộng (Scalability) cho kiến trúc. Các mục tiêu chính bao gồm:\nTự động mở rộng \u0026amp; Cân bằng tải – Cấu hình hệ thống để xử lý tải lưu lượng thay đổi tự động bằng ASG và ALB. Kiến trúc Decoupling (Tách rời) – Sử dụng SQS và SNS để cho phép giao tiếp không đồng bộ giữa các vi dịch vụ. Giám sát mạng – Tăng cường khả năng quan sát bằng cách ghi lại và phân tích lưu lượng mạng với VPC Flow Logs. Tuần này biến đổi cơ sở hạ tầng tĩnh thành một hệ thống động, bền vững, có khả năng tự phục hồi và mở rộng theo nhu cầu.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Tìm hiểu về các khái niệm High Availability, Fault Tolerance và Elasticity\n- Giới thiệu về Auto Scaling Group (ASG) và Elastic Load Balancer (ELB) 20/10/2025 20/10/2025 AWS Journey Thứ Ba - Thực hành tạo Auto Scaling Group cho EC2 instance\n- Thiết lập launch template, scaling policy và theo dõi mục tiêu (target tracking) 21/10/2025 21/10/2025 AWS Journey Thứ Tư - Tạo và cấu hình Application Load Balancer (ALB)\n- Kết nối ALB với ASG để phân phối tải\n- Kiểm tra truy cập website qua ALB DNS 22/10/2025 22/10/2025 AWS Journey Thứ Năm - Làm quen với dịch vụ Amazon SQS và SNS\n- Tạo SQS queue, SNS topic và subscription\n- Gửi và nhận thông báo giữa các thành phần 23/10/2025 23/10/2025 AWS Journey Thứ Sáu - Bật VPC Flow Logs để giám sát lưu lượng mạng\n- Phân tích nhật ký trong CloudWatch Logs\n- Tổng hợp kiến thức về độ tin cậy \u0026amp; mở rộng 24/10/2025 24/10/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 Auto Scaling Group (ASG) Launch Template: Tạo mẫu định nghĩa AMI, Loại instance (t2.micro) và Security Groups. Chính sách mở rộng (Scaling Policies): Triển khai Target Tracking Scaling Policy để duy trì mức sử dụng CPU trung bình ở 50%. Dung lượng: Cấu hình Min: 2, Max: 4, Desired: 2 để đảm bảo tính sẵn sàng cao trên nhiều Availability Zones. 3.2 Application Load Balancer (ALB) Target Group: Tạo nhóm đích cho lưu lượng HTTP (Cổng 80). Quy tắc Listener: Cấu hình ALB để lắng nghe HTTP và chuyển tiếp lưu lượng đến Target Group của ASG. Kiểm tra sức khỏe (Health Checks): Cấu hình đường dẫn /index.html để đảm bảo chỉ các instance khỏe mạnh mới nhận được lưu lượng. DNS: Xác thực quyền truy cập bằng tên DNS tự tạo của ALB (my-loadbalancer-123.region.elb.amazonaws.com). 3.3 Tách rời với SQS \u0026amp; SNS SNS (Simple Notification Service): Tạo Topic (OrderAlerts) và đăng ký địa chỉ email để nhận thông báo. SQS (Simple Queue Service): Tạo Hàng đợi tiêu chuẩn (OrderQueue). Mô hình Fan-out: Đăng ký SQS queue vào SNS topic. Xuất bản một tin nhắn lên SNS và xác minh nó xuất hiện trong cả hộp thư Email và hàng đợi SQS. 3.4 VPC Flow Logs \u0026amp; Giám sát Thiết lập: Bật Flow Logs cho VPC, gửi dữ liệu đến CloudWatch Logs. Phân tích: Sử dụng CloudWatch Log Insights để truy vấn lưu lượng: Xác định lưu lượng bị từ chối (REJECT) do chặn Security Group. Theo dõi các nỗ lực kết nối SSH. Phân tích luồng lưu lượng nội bộ giữa các subnets. 4. Thành tựu Đến cuối Tuần 7, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Hiểu rõ mô hình Tính sẵn sàng cao và cách duy trì thời gian hoạt động của hệ thống khi gặp sự cố. Triển khai thành công Auto Scaling Group + Load Balancer để tự động mở rộng dung lượng EC2. Cấu hình SQS/SNS để giao tiếp hàng đợi và thông báo tin cậy. Bật và đọc hiểu VPC Flow Logs, phân tích lưu lượng mạng trong CloudWatch. ✔ Phát triển kỹ năng Nắm vững mối quan hệ giữa Load Balancers và Auto Scaling Groups. Học cách giả lập tải (sử dụng công cụ stress) để kích hoạt sự kiện mở rộng (scaling events). Có kinh nghiệm trong thiết kế kiến trúc \u0026ldquo;Loose Coupling\u0026rdquo; (Kết nối lỏng lẻo). Cải thiện kỹ năng khắc phục sự cố mạng thông qua phân tích nhật ký (log). 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Unhealthy Targets trong ALB\nVấn đề: Các instance EC2 trong Target Group hiển thị trạng thái \u0026ldquo;Unhealthy\u0026rdquo;. Giải pháp: Security Group trên EC2 không cho phép lưu lượng từ Security Group của Load Balancer. Đã cập nhật quy tắc Inbound để cho phép HTTP từ SG của ALB. Thách thức 2: ASG không thu hẹp (Scale Down)\nVấn đề: Sau khi test tải, các instances vẫn chạy lâu hơn dự kiến. Giải pháp: Hiểu về khái niệm Cooldown Period (Thời gian hạ nhiệt). ASG đang chờ hết thời gian cooldown mặc định (300 giây) trước khi chấm dứt instances để tránh hiện tượng \u0026ldquo;dao động\u0026rdquo; (thrashing). Thách thức 3: Khả năng hiển thị tin nhắn SQS\nVấn đề: Tin nhắn đã được xử lý nhưng lại xuất hiện lại trong hàng đợi. Giải pháp: Điều chỉnh Visibility Timeout để khớp với thời gian xử lý của ứng dụng tiêu thụ (consumer). "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 8 – AWS Journey 1. Mục tiêu hàng tuần Tuần 8 đóng vai trò là giai đoạn tổng kết và củng cố toàn diện. Mục tiêu chính là hệ thống hóa tất cả kiến thức đã học trong 7 tuần qua dưới góc nhìn của AWS Well-Architected Framework (Khung kiến trúc tốt). Các mục tiêu chính bao gồm:\nWell-Architected Framework: Hiểu sâu về 5 trụ cột (Vận hành xuất sắc, Bảo mật, Tin cậy, Hiệu quả hiệu suất, Tối ưu hóa chi phí). Củng cố kiến trúc: Ôn tập các phương pháp hay nhất về Bảo mật (IAM, KMS), Khả năng phục hồi (Multi-AZ, DR) và Tối ưu hóa. Thiết kế tổng thể: Thiết kế một cơ sở hạ tầng hoàn chỉnh tích hợp các dịch vụ cốt lõi (EC2, S3, RDS, VPC, Lambda, CloudFront) và đánh giá theo tiêu chuẩn AWS. Tuần này chuyển tiếp từ việc học các dịch vụ riêng lẻ sang thiết kế các hệ thống mạnh mẽ, sẵn sàng cho môi trường thực tế (production).\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Tổng quan về AWS Well-Architected Framework \u0026amp; 5 trụ cột\n- Xác định vai trò và tầm quan trọng của từng trụ cột trong thiết kế hệ thống 27/10/2025 27/10/2025 AWS Journey Thứ Ba - Ôn tập Thiết kế Kiến trúc Bảo mật\n- Chuyên sâu: IAM, MFA, SCP, KMS, WAF, Shield, GuardDuty, Security Groups so với NACLs 28/10/2025 28/10/2025 AWS Journey Thứ Tư - Ôn tập Thiết kế Kiến trúc Bền vững (Resilient)\n- Chủ đề: Multi-AZ, Multi-Region, Chiến lược DR, Route 53, Sao lưu \u0026amp; Khôi phục 29/10/2025 29/10/2025 AWS Journey Thứ Năm - Ôn tập Tối ưu hóa Hiệu suất và Chi phí\n- Chủ đề: Auto Scaling, Global Accelerator, Phân cấp S3, Savings Plans 30/10/2025 30/10/2025 AWS Journey Thứ Sáu - Thực hành tổng hợp: Xây dựng kiến trúc mẫu full-stack\n- Đánh giá theo 5 tiêu chí của Well-Architected Framework\n- Viết báo cáo tổng kết tuần 31/10/2025 31/10/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 Đánh giá Kiến trúc Bảo mật (Trụ cột Security) Phòng thủ theo chiều sâu (Defense in Depth): Thiết kế mô hình bảo mật đa lớp: Biên (Edge): AWS WAF \u0026amp; Shield (chống DDoS). VPC: Subnet Public/Private, NACLs (Stateless), Security Groups (Stateful). Danh tính: IAM Users với MFA, Roles cho dịch vụ, Nguyên tắc đặc quyền tối thiểu. Dữ liệu: KMS để mã hóa khi nghỉ (EBS/S3/RDS), TLS/ACM để mã hóa đường truyền. 3.2 Độ tin cậy \u0026amp; Khả năng phục hồi (Trụ cột Reliability) Tính sẵn sàng cao (HA): Thiết kế triển khai Multi-AZ cho EC2 (qua ASG) và RDS (Primary/Standby). Khôi phục thảm họa (DR): Rà soát 4 chiến lược DR: Backup \u0026amp; Restore (Rẻ nhất, RTO cao nhất). Pilot Light. Warm Standby. Multi-Site Active/Active (Đắt nhất, RTO thấp nhất). 3.3 Hiệu suất \u0026amp; Chi phí (Trụ cột Efficiency \u0026amp; Optimization) Hiệu suất: Triển khai CloudFront để lưu đệm tại biên (edge caching) và Global Accelerator để tối ưu hóa định tuyến giảm độ trễ. Chi phí: Phân tích S3 Lifecycle Policies (Standard -\u0026gt; IA -\u0026gt; Glacier) để tự động tiết kiệm lưu trữ. Đánh giá Compute Savings Plans so với Reserved Instances cho khối lượng công việc dài hạn. Sử dụng AWS Cost Explorer để xác định tài nguyên \u0026ldquo;zombie\u0026rdquo; (EIP không gắn kết, ELB nhàn rỗi). 3.4 Thực hành Kiến trúc Capstone Thiết kế Ứng dụng Web 3 tầng (3-Tier Web App): Tầng trình bày: CloudFront + S3 (tài sản tĩnh) / ALB (yêu cầu động). Tầng logic: EC2 Auto Scaling Group trong Private Subnets. Tầng dữ liệu: RDS Multi-AZ + DynamoDB. Thực hiện tự đánh giá bằng công cụ AWS Well-Architected Tool để xác định các rủi ro (High/Medium Risk Issues). 4. Thành tựu Đến cuối Tuần 8, các kết quả sau đã đạt được:\n✔ Làm chủ khái niệm Hiểu sâu và hệ thống hóa kiến thức về AWS Well-Architected Framework. Có khả năng phân tích sự đánh đổi (trade-offs) giữa Chi phí, Hiệu suất và Độ tin cậy. ✔ Củng cố kỹ thuật Củng cố 4 nhóm kiến trúc cốt lõi: Bảo mật, Bền vững, Hiệu suất và Tối ưu hóa chi phí. Nắm vững sự tương tác giữa các dịch vụ cốt lõi (ví dụ: cách CloudWatch kích hoạt Lambda để khắc phục sự cố). ✔ Ứng dụng thực tế Thực hành thiết kế một cơ sở hạ tầng hoàn chỉnh theo tiêu chuẩn công nghiệp từ con số 0. Học cách thực hiện tự đánh giá và rà soát kiến trúc. 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Phân tích sự đánh đổi (Trade-off)\nVấn đề: Khó khăn khi chọn giữa \u0026ldquo;Hiệu suất tối đa\u0026rdquo; và \u0026ldquo;Chi phí thấp nhất\u0026rdquo; (ví dụ: DynamoDB Provisioned vs. On-Demand). Giải pháp: Sử dụng Well-Architected Framework để ưu tiên yêu cầu nghiệp vụ (ví dụ: nếu lưu lượng không thể dự đoán, On-Demand tốt hơn dù chi phí đơn vị có thể cao hơn). Thách thức 2: Sự phức tạp của chiến lược DR\nVấn đề: Nhầm lẫn sự khác biệt nhỏ giữa \u0026ldquo;Pilot Light\u0026rdquo; và \u0026ldquo;Warm Standby\u0026rdquo;. Giải pháp: Tạo bảng so sánh tập trung vào mục tiêu RTO/RPO và số lượng tài nguyên hoạt động để phân biệt rõ ràng. Thách thức 3: Xung đột Security Group vs. NACL\nVấn đề: Khắc phục sự cố kết nối khi NACL chặn lưu lượng trả về (cổng ephemeral). Giải pháp: Củng cố hiểu biết rằng NACL là phi trạng thái (stateless) và yêu cầu quy tắc cho phép rõ ràng cho cả chiều vào (inbound) và chiều ra (outbound). "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 9 – AWS Journey 1. Mục tiêu hàng tuần Trong Tuần 9, trọng tâm mở rộng sang lĩnh vực Dữ liệu \u0026amp; Phân tích (Data \u0026amp; Analytics). Mục tiêu chính là hiểu quy trình dữ liệu đầu cuối (end-to-end) trên AWS, từ thu thập đến trực quan hóa. Các mục tiêu chính bao gồm:\nKiến trúc Data Lake – Xây dựng kho lưu trữ có khả năng mở rộng bằng Amazon S3. ETL \u0026amp; Danh mục dữ liệu – Sử dụng AWS Glue để khám phá và lập danh mục siêu dữ liệu (metadata). Truy vấn không máy chủ (Serverless Querying) – Phân tích dữ liệu trực tiếp trong S3 bằng Amazon Athena (SQL). Trí tuệ doanh nghiệp (BI) – Trực quan hóa thông tin chi tiết bằng Amazon QuickSight. Tuần này trình bày cách biến dữ liệu thô thành thông tin kinh doanh hữu ích bằng các công cụ phân tích serverless.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Giới thiệu hệ sinh thái Data \u0026amp; Analytics trên AWS\n- Hiểu khái niệm Data Lake, quy trình ETL và cách kết nối nguồn dữ liệu 03/11/2025 03/11/2025 AWS Journey Thứ Ba - Tạo Data Lake trên Amazon S3\n- Cấu trúc thư mục, quyền truy cập\n- Thiết lập AWS Glue Crawler để xác định schema dữ liệu 04/11/2025 04/11/2025 AWS Journey Thứ Tư - Thực hành AWS Athena để truy vấn dữ liệu trong Data Lake\n- Viết câu lệnh SQL cơ bản và xuất kết quả ra S3 05/11/2025 05/11/2025 AWS Journey Thứ Năm - Giới thiệu và thực hành với Amazon QuickSight\n- Kết nối QuickSight với Athena\n- Tạo dashboard đơn giản với biểu đồ và bảng tổng hợp 06/11/2025 06/11/2025 AWS Journey Thứ Sáu - Ôn tập \u0026amp; củng cố kiến thức tuần (Thu thập → xử lý → phân tích)\n- So sánh Glue/Athena với công cụ truyền thống\n- Viết báo cáo tổng kết thực hành 07/11/2025 07/11/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 Thiết lập Data Lake (Amazon S3) Chiến lược lưu trữ: Tạo S3 bucket với cấu trúc thư mục logic (ví dụ: raw-data/, processed-data/). Nhập dữ liệu: Tải lên các tập dữ liệu mẫu (file CSV/JSON nhật ký bán hàng) vào thư mục raw-data. Bảo mật: Áp dụng \u0026ldquo;Block Public Access\u0026rdquo; và đảm bảo IAM roles sẵn sàng cho Glue và Athena truy cập. 3.2 Khám phá Metadata (AWS Glue) Glue Crawler: Cấu hình Crawler để quét S3 bucket. IAM Role: Tạo service role cấp quyền cho Glue đọc S3 và ghi vào Glue Data Catalog. Data Catalog: Chạy thành công crawler, tự động phát hiện schema (cột, kiểu dữ liệu) và tạo định nghĩa bảng trong Glue Database. 3.3 Truy vấn không máy chủ (Amazon Athena) Cấu hình: Thiết lập vị trí lưu kết quả truy vấn trong S3 (s3://my-bucket/athena-results/). Thao tác SQL: Thực thi các truy vấn SQL chuẩn trên bảng Glue: SELECT product_category, SUM(amount) as total_sales FROM sales_data GROUP BY product_category; Xác minh: Xác nhận rằng Athena có thể truy vấn dữ liệu CSV trực tiếp mà không cần nạp vào máy chủ cơ sở dữ liệu. 3.4 Trực quan hóa dữ liệu (Amazon QuickSight) Tạo Dataset: Chọn Athena làm nguồn dữ liệu và nhập bảng đã tạo ở các bước trước. SPICE: Nhập dữ liệu vào bộ nhớ đệm SPICE để hiển thị nhanh hơn. Dashboarding: Xây dựng bảng điều khiển chứa: Biểu đồ cột: Doanh số theo khu vực. Biểu đồ tròn: Nhân khẩu học khách hàng. KPI: Tổng doanh thu. 4. Thành tựu Đến cuối Tuần 9, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Xây dựng thành công Data Lake Serverless sử dụng S3. Tự động hóa việc khám phá cấu trúc dữ liệu bằng AWS Glue Crawlers. Thực hiện phân tích SQL tùy ý bằng Athena mà không cần cấp phát máy chủ. Tạo BI Dashboard trực quan trong QuickSight để trình bày thông tin chi tiết. ✔ Phát triển kỹ năng Hiểu sự tách biệt giữa Tính toán (Athena) và Lưu trữ (S3). Có kinh nghiệm với khái niệm Schema-on-Read so với Schema-on-Write truyền thống. Học cách quản lý quyền IAM giữa các dịch vụ Phân tích (QuickSight \u0026lt;-\u0026gt; Athena \u0026lt;-\u0026gt; S3). 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Lỗi vị trí đầu ra Athena\nVấn đề: Truy vấn thất bại với lỗi \u0026ldquo;No output location provided\u0026rdquo;. Giải pháp: Cấu hình \u0026ldquo;Query Result Location\u0026rdquo; trong cài đặt Athena trỏ đến một thư mục S3 hợp lệ. Thách thức 2: Quyền truy cập QuickSight\nVấn đề: QuickSight không thể truy cập dữ liệu trong S3 bucket. Giải pháp: Truy cập \u0026ldquo;Manage QuickSight\u0026rdquo; \u0026gt; \u0026ldquo;Security \u0026amp; Permissions\u0026rdquo; và tích chọn thủ công vào S3 bucket chứa dữ liệu. Thách thức 3: Phân loại sai của Glue Crawler\nVấn đề: Crawler phân loại dữ liệu CSV không chính xác do vấn đề về tiêu đề (header). Giải pháp: Chỉnh sửa trình phân loại tùy chỉnh (custom classifier) trong Glue để nhận diện đúng hàng tiêu đề CSV. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại phần này, bạn cần tóm tắt các nội dung trong workshop mà bạn dự tính sẽ làm.\nIoT Weather Platform for Lab Research Giải pháp AWS Serverless hợp nhất cho giám sát thời tiết thời gian thực 1. Tóm tắt điều hành IoT Weather Platform được thiết kế dành cho nhóm ITea Lab tại TP. Hồ Chí Minh nhằm nâng cao khả năng thu thập và phân tích dữ liệu thời tiết. Nền tảng hỗ trợ tối đa 5 trạm thời tiết, có khả năng mở rộng lên 10–15 trạm, sử dụng thiết bị biên Raspberry Pi kết hợp cảm biến ESP32 để truyền dữ liệu qua MQTT. Nền tảng tận dụng các dịch vụ AWS Serverless để cung cấp giám sát thời gian thực, phân tích dự đoán và tiết kiệm chi phí, với quyền truy cập giới hạn cho 5 thành viên phòng lab thông qua Amazon Cognito.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác trạm thời tiết hiện tại yêu cầu thu thập dữ liệu thủ công, khó quản lý khi có nhiều trạm. Không có hệ thống tập trung cho dữ liệu hoặc phân tích thời gian thực, và các nền tảng bên thứ ba thường tốn kém và quá phức tạp.\nGiải pháp\nNền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT, AWS Lambda và API Gateway để xử lý, Amazon S3 để lưu trữ (bao gồm data lake), và AWS Glue Crawlers cùng các tác vụ ETL để trích xuất, chuyển đổi, tải dữ liệu từ S3 data lake sang một S3 bucket khác để phân tích. AWS Amplify với Next.js cung cấp giao diện web, và Amazon Cognito đảm bảo quyền truy cập an toàn. Tương tự như Thingsboard và CoreIoT, người dùng có thể đăng ký thiết bị mới và quản lý kết nối, nhưng nền tảng này hoạt động ở quy mô nhỏ hơn và phục vụ mục đích sử dụng nội bộ. Các tính năng chính bao gồm bảng điều khiển thời gian thực, phân tích xu hướng và chi phí vận hành thấp.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp tạo nền tảng cơ bản để các thành viên phòng lab phát triển một nền tảng IoT lớn hơn, đồng thời cung cấp nguồn dữ liệu cho những người nghiên cứu AI phục vụ huấn luyện mô hình hoặc phân tích. Nền tảng giảm bớt báo cáo thủ công cho từng trạm thông qua hệ thống tập trung, đơn giản hóa quản lý và bảo trì, đồng thời cải thiện độ tin cậy dữ liệu. Chi phí hàng tháng ước tính 0,66 USD (theo AWS Pricing Calculator), tổng cộng 7,92 USD cho 12 tháng. Tất cả thiết bị IoT đã được trang bị từ hệ thống trạm thời tiết hiện tại, không phát sinh chi phí phát triển thêm. Thời gian hoàn vốn 6–12 tháng nhờ tiết kiệm đáng kể thời gian thao tác thủ công.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 10 – AWS Journey 1. Mục tiêu hàng tuần Trong Tuần 10, quá trình khám phá mở rộng sang lĩnh vực Trí tuệ nhân tạo (AI) và Học máy (ML) của AWS. Mục tiêu chính là phân biệt giữa việc xây dựng các mô hình tùy chỉnh và sử dụng các dịch vụ AI được huấn luyện trước. Các mục tiêu chính bao gồm:\nHệ sinh thái AI AWS – Hiểu bối cảnh của các dịch vụ ML (SageMaker) so với Dịch vụ AI (Rekognition, Comprehend, Kendra). Amazon SageMaker – Trải nghiệm vòng đời ML đầy đủ: Xây dựng (Build), Huấn luyện (Train) và Triển khai (Deploy). Thị giác máy tính \u0026amp; NLP – Triển khai phân tích hình ảnh và xử lý ngôn ngữ tự nhiên mà không cần chuyên môn sâu về khoa học dữ liệu bằng cách sử dụng AWS API. Tìm kiếm thông minh – Thiết lập khả năng tìm kiếm doanh nghiệp với Amazon Kendra. Tuần này làm nổi bật cách AWS dân chủ hóa AI, cho phép các nhà phát triển thêm trí thông minh vào ứng dụng thông qua các lệnh gọi API hoặc xây dựng các mô hình tùy chỉnh với cơ sở hạ tầng được quản lý.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Tổng quan về AI/ML trên AWS\n- Tìm hiểu các dịch vụ hỗ trợ ML: SageMaker, Rekognition, Comprehend, Kendra, Translate, Polly 10/11/2025 10/11/2025 AWS Journey Thứ Ba - Thực hành với Amazon SageMaker:\n- Tạo Notebook Instance\n- Huấn luyện mô hình đơn giản (Hồi quy tuyến tính / Phân loại ảnh)\n- Triển khai endpoint và kiểm tra dự đoán 11/11/2025 11/11/2025 AWS Journey Thứ Tư - Làm quen với Amazon Rekognition\n- Demo nhận diện khuôn mặt và vật thể trong ảnh/video\n- Tích hợp Rekognition API vào ứng dụng web nhỏ 12/11/2025 12/11/2025 AWS Journey Thứ Năm - Thực hành Amazon Comprehend (xử lý ngôn ngữ tự nhiên)\n- Thử nghiệm Amazon Kendra (tìm kiếm thông minh theo ngữ cảnh)\n- So sánh ưu điểm và hạn chế của từng dịch vụ 13/11/2025 13/11/2025 AWS Journey Thứ Sáu - Tổng hợp kiến thức Tuần 10 (Quy trình phát triển AI/ML)\n- Ứng dụng thực tế của AI/ML trong doanh nghiệp\n- Viết báo cáo kết quả thực hành và hướng mở rộng 14/11/2025 14/11/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 Amazon SageMaker (Custom ML) Notebook Instance: Khởi chạy một instance Jupyter Notebook ml.t2.medium. Huấn luyện: Sử dụng thuật toán tích hợp sẵn (như XGBoost) để huấn luyện mô hình trên tập dữ liệu mẫu (ví dụ: dự đoán giá nhà hoặc bộ dữ liệu MNIST). Triển khai: Triển khai mô hình đã huấn luyện tới một HTTPS Endpoint thời gian thực. Suy luận (Inference): Gọi endpoint bằng Python (Boto3) để tạo dự đoán từ dữ liệu mới. 3.2 Amazon Rekognition (Thị giác máy tính) Phân tích hình ảnh: Tải ảnh lên S3 và sử dụng API DetectLabels để nhận diện vật thể (ví dụ: \u0026ldquo;Xe hơi\u0026rdquo;, \u0026ldquo;Cây\u0026rdquo;, \u0026ldquo;Người\u0026rdquo;) với điểm tin cậy. Phân tích khuôn mặt: Sử dụng DetectFaces để ước tính độ tuổi, cảm xúc và giới tính. Tích hợp: Viết một script đơn giản kích hoạt hàm Lambda khi có ảnh được tải lên S3 để tự động gắn thẻ bằng Rekognition. 3.3 Amazon Comprehend (NLP) Phân tích cảm xúc: Xử lý văn bản đánh giá của khách hàng để xác định cảm xúc (Tích cực, Tiêu cực, Trung lập). Nhận diện thực thể: Trích xuất các thực thể cụ thể (Ngày tháng, Địa điểm, Tên riêng) từ các tài liệu văn bản phi cấu trúc. 3.4 Amazon Kendra (Tìm kiếm thông minh) Tạo chỉ mục: Tạo Kendra Index (Phiên bản Developer). Nguồn dữ liệu: Kết nối một S3 bucket chứa các file PDF hướng dẫn sử dụng làm cơ sở tri thức. Truy vấn: Thử nghiệm các truy vấn ngôn ngữ tự nhiên (ví dụ: \u0026ldquo;Làm thế nào để reset thiết bị?\u0026rdquo;) trong bảng điều khiển và nhận được câu trả lời chính xác được trích xuất từ tài liệu. 4. Thành tựu Đến cuối Tuần 10, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Thành công huấn luyện và lưu trữ một mô hình Học máy sử dụng Amazon SageMaker. Triển khai các tính năng Thị giác máy tính (Nhận diện khuôn mặt/Vật thể) thông qua lệnh gọi API. Trích xuất thông tin chi tiết từ văn bản bằng Amazon Comprehend. Thiết lập công cụ tìm kiếm tài liệu hoạt động tốt bằng Amazon Kendra. ✔ Phát triển kỹ năng Hiểu rõ sự phân biệt giữa Dịch vụ AI (API cấp cao cho nhà phát triển) và Dịch vụ ML (SageMaker cho Nhà khoa học dữ liệu). Có kinh nghiệm về chi phí Suy luận mô hình (Inference) và quản lý endpoint. Học cách tích hợp khả năng AI vào các ứng dụng hiện có bằng AWS SDK. 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Quản lý chi phí SageMaker\nVấn đề: SageMaker Notebooks và Endpoints tính phí theo giờ ngay cả khi nhàn rỗi. Giải pháp: Tạo quy trình \u0026ldquo;Dọn dẹp\u0026rdquo; để xóa Endpoints và Stop Notebook instances ngay sau khi hoàn thành bài lab để tránh hóa đơn ngoài ý muốn. Thách thức 2: Quyền IAM cho Rekognition\nVấn đề: Lỗi AccessDeniedException khi Rekognition cố gắng đọc ảnh từ S3 bucket. Giải pháp: Cập nhật Bucket Policy và IAM Role để cấp quyền s3:GetObject rõ ràng cho user/role đang gọi Rekognition API. Thách thức 3: Thời gian lập chỉ mục Kendra\nVấn đề: Kendra mất khá nhiều thời gian (30+ phút) để tạo chỉ mục và đồng bộ dữ liệu. Giải pháp: Hiểu rằng Kendra là dịch vụ cấp doanh nghiệp cần thời gian cấp phát; lên kế hoạch tác vụ để làm việc với Comprehend trong khi chờ Kendra khởi tạo. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 11 – AWS Journey 1. Mục tiêu hàng tuần Tuần 11 tập trung vào Hiện đại hóa Ứng dụng thông qua Kiến trúc Serverless (Không máy chủ). Mục tiêu chính là chuyển đổi từ việc quản lý cơ sở hạ tầng (EC2) sang tập trung vào mã nguồn và logic nghiệp vụ bằng cách sử dụng các dịch vụ hướng sự kiện. Các mục tiêu chính bao gồm:\nMô hình Serverless – Hiểu sự chuyển dịch từ kiến trúc Nguyên khối (Monolithic) sang Vi dịch vụ (Microservices) và lợi ích của \u0026ldquo;No-Ops\u0026rdquo;. Bộ công cụ Serverless cốt lõi – Làm chủ AWS Lambda (Tính toán), API Gateway (Giao diện) và DynamoDB (Dữ liệu NoSQL). Bảo mật \u0026amp; Xác thực – Triển khai quản lý danh tính người dùng với Amazon Cognito. Cơ sở hạ tầng dưới dạng mã – Sử dụng AWS Serverless Application Model (SAM) để định nghĩa và triển khai tài nguyên serverless. Tuần này cung cấp bộ kỹ năng để xây dựng các ứng dụng có khả năng mở rộng cao, tiết kiệm chi phí và \u0026ldquo;thu nhỏ về 0\u0026rdquo; khi không sử dụng.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Giới thiệu về khái niệm Hiện đại hóa và Serverless\n- So sánh kiến trúc Nguyên khối và Vi dịch vụ\n- Phân tích lợi ích: Chi phí, Khả năng mở rộng, Vận hành 17/11/2025 17/11/2025 AWS Journey Thứ Ba - Thực hành AWS Lambda: tạo hàm, cấu hình triggers (S3/APIGW)\n- Xem nhật ký log trong CloudWatch\n- Triển khai logic xử lý API cơ bản 18/11/2025 18/11/2025 AWS Journey Thứ Tư - Tích hợp API Gateway với Lambda (tạo REST API)\n- Kết nối dữ liệu với DynamoDB (Thao tác CRUD)\n- Test API sử dụng Postman 19/11/2025 19/11/2025 AWS Journey Thứ Năm - Cấu hình Cognito để xác thực người dùng (User Pool)\n- Tích hợp xác thực Cognito vào API Gateway\n- Quản lý quyền truy cập qua IAM Role 20/11/2025 20/11/2025 AWS Journey Thứ Sáu - Thực hành triển khai Serverless App hoàn chỉnh dùng AWS SAM\n- Kiểm thử, ghi nhật ký và tối ưu hóa hiệu năng\n- Tổng hợp kiến thức và báo cáo tuần 21/11/2025 21/11/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật 3.1 AWS Lambda \u0026amp; Logic Runtime: Tạo hàm Lambda sử dụng Python 3.9. Handler: Triển khai hàm lambda_handler(event, context) để phân tích dữ liệu đầu vào JSON. Triggers: Cấu hình API Gateway làm nguồn sự kiện kích hoạt hàm. Logging: Sử dụng lệnh print() để gửi nhật ký có cấu trúc đến CloudWatch phục vụ gỡ lỗi. 3.2 Tích hợp API Gateway \u0026amp; DynamoDB Loại API: Xây dựng REST API. Tích hợp: Sử dụng Lambda Proxy Integration để chuyển toàn bộ đối tượng yêu cầu HTTP sang hàm xử lý. Cơ sở dữ liệu: Tạo bảng DynamoDB (Items) với ItemId làm Khóa phân vùng (Partition Key). Sử dụng thư viện boto3 trong Lambda để thực hiện các lệnh put_item, get_item và scan dựa trên phương thức HTTP (POST, GET). 3.3 Bảo mật với Amazon Cognito User Pool: Tạo User Pool để xử lý đăng ký và đăng nhập. App Client: Tạo client ID cho ứng dụng. Authorizer: Cấu hình Cognito User Pool Authorizer trong API Gateway. Xác thực: Xác minh rằng các yêu cầu API không có mã thông báo (token) Authorization (JWT) hợp lệ sẽ bị từ chối với lỗi 401 Unauthorized. 3.4 AWS SAM (Mô hình Ứng dụng Serverless) Template: Định nghĩa tài nguyên (Hàm, API, Bảng) trong tệp template.yaml. Build: Chạy sam build để biên dịch các gói phụ thuộc. Deploy: Thực hiện sam deploy --guided để đóng gói mã lên S3 và tự động tạo CloudFormation stack. Kiểm thử cục bộ: Sử dụng sam local invoke để kiểm tra hàm trên máy cá nhân trước khi triển khai. 4. Thành tựu Đến cuối Tuần 11, các kết quả sau đã đạt được:\n✔ Thành công về mặt chức năng Chuyển đổi thành công từ quản lý máy chủ sang triển khai các hàm (functions). Xây dựng một Serverless CRUD API hoạt động hoàn chỉnh. Bảo mật các endpoint API bằng JWT Tokens từ Cognito. Tự động hóa triển khai bằng AWS SAM, thay thế các thao tác thủ công trên console. ✔ Phát triển kỹ năng Hiểu thấu đáo mô hình Kiến trúc Hướng sự kiện (Event-Driven Architecture). Học cách xử lý các hạn chế của tính toán Phi trạng thái (Stateless). Làm chủ quy trình phân rã vấn đề thành các vi dịch vụ (Dịch vụ xác thực, Dịch vụ dữ liệu, Dịch vụ logic). 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Lỗi CORS\nVấn đề: Gọi API từ trình duyệt web (frontend) dẫn đến lỗi Chia sẻ tài nguyên chéo nguồn (CORS). Giải pháp: Bật CORS trong cài đặt API Gateway và đảm bảo hàm Lambda trả về header Access-Control-Allow-Origin: * trong đối tượng phản hồi. Thách thức 2: Quyền hạn Lambda\nVấn đề: Lỗi AccessDeniedException khi Lambda cố gắng ghi dữ liệu vào DynamoDB. Giải pháp: Cập nhật IAM Execution Role của Lambda để bao gồm quyền dynamodb:PutItem và dynamodb:GetItem cho ARN của bảng cụ thể. Thách thức 3: Khởi động lạnh (Cold Starts)\nVấn đề: Cuộc gọi API đầu tiên sau một thời gian không hoạt động mất 2-3 giây để phản hồi. Giải pháp: Chấp nhận đây là sự đánh đổi của Serverless. Tối ưu hóa các thư viện import trong mã Python để giảm thời gian khởi tạo. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "📘 Báo cáo công việc Tuần 12 – AWS Journey 1. Mục tiêu hàng tuần Tuần 12 đánh dấu sự kết thúc của lộ trình học tập AWS. Mục tiêu chính là tổng hợp và ứng dụng tất cả các kỹ năng đã học trong 11 tuần qua vào một Dự án Cuối khóa (Capstone Project) toàn diện. Các mục tiêu chính bao gồm:\nÔn tập tổng thể – Rà soát lại các dịch vụ cốt lõi (EC2, VPC, S3, RDS, Lambda) để đảm bảo hiểu sâu. Dự án Capstone – Thiết kế, xây dựng và triển khai một \u0026ldquo;Hệ thống Xử lý Đơn hàng E-Commerce\u0026rdquo; hoàn chỉnh từ con số không. Vận hành xuất sắc – Triển khai CI/CD, Giám sát và các phương pháp bảo mật tốt nhất. Tự đánh giá – Đánh giá kiến trúc dựa trên Well-Architected Framework và chuẩn bị cho kỳ thi chứng chỉ. Tuần này chuyển đổi vị thế từ \u0026ldquo;Người học\u0026rdquo; sang \u0026ldquo;Kỹ sư/Kiến trúc sư đám mây\u0026rdquo; sẵn sàng cho các thách thức thực tế.\n2. Tóm tắt công việc chi tiết 🗂 Bảng hoạt động Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tham khảo Thứ Hai - Ôn tập dịch vụ cốt lõi: EC2, S3, RDS, DynamoDB, IAM, VPC, Lambda, CloudFront\n- Xác định yêu cầu và kiến trúc cho dự án cuối khóa 24/11/2025 24/11/2025 AWS Journey Thứ Ba - Bắt đầu triển khai dự án:\n- Thiết kế VPC (Subnet Public/Private), Security Groups\n- Cấu hình S3 cho tài nguyên tĩnh, CloudFront cho CDN 25/11/2025 25/11/2025 AWS Journey Thứ Tư - Triển khai Backend:\n- Xây dựng Lambda functions và API Gateway\n- Kết nối Database (RDS/DynamoDB) và xử lý logic\n- Tích hợp CloudWatch Logs \u0026amp; Alarms 26/11/2025 26/11/2025 AWS Journey Thứ Năm - Hoàn thiện dự án:\n- Thêm xác thực Cognito (Đăng ký/Đăng nhập)\n- Hoàn tất pipeline CI/CD (CodePipeline/CodeBuild)\n- Kiểm thử hệ thống đầu cuối (End-to-end) 27/11/2025 27/11/2025 AWS Journey Thứ Sáu - Viết báo cáo và tài liệu cuối kỳ\n- Chuẩn bị bài thuyết trình (Sơ đồ kiến trúc, phân tích chi phí, bảo mật)\n- Tổng kết toàn bộ hành trình và tự đánh giá năng lực 28/11/2025 28/11/2025 AWS Journey 3. Chi tiết triển khai kỹ thuật (Dự án Capstone) 3.1 Phạm vi dự án: \u0026ldquo;Serverless E-Commerce Backend\u0026rdquo; Tổng quan kiến trúc: Ứng dụng web 3 tầng (3-tier) sử dụng công nghệ serverless. Frontend: Lưu trữ trên S3 + phân phối qua CloudFront. Backend: API Gateway + Lambda. Cơ sở dữ liệu: DynamoDB (Danh mục sản phẩm) + RDS MySQL (Lịch sử đơn hàng). Xác thực: Amazon Cognito. 3.2 Thiết lập cơ sở hạ tầng Thiết kế VPC: Tạo VPC tùy chỉnh với 2 Public Subnets (NAT Gateway, Load Balancer) và 2 Private Subnets (Lambda, RDS). Security Groups: Định nghĩa quy tắc nghiêm ngặt: RDS chỉ chấp nhận traffic từ Lambda SG trên cổng 3306. Lambda chỉ chấp nhận traffic từ các VPC endpoints nội bộ. 3.3 Logic ứng dụng \u0026amp; Dữ liệu Hàm Lambda: Phát triển các hàm Python cho CreateOrder, GetProducts, và ProcessPayment. Tích hợp Database: Sử dụng Boto3 để quét (scan) DynamoDB lấy thông tin sản phẩm. Sử dụng PyMySQL để thực hiện giao dịch SQL ghi đơn hàng vào RDS. Giám sát: Tạo CloudWatch Dashboard để trực quan hóa Độ trễ API và Tỷ lệ lỗi (4xx/5xx). 3.4 Tự động hóa \u0026amp; Vận hành CI/CD: Xây dựng đường ống bằng AWS CodePipeline: Nguồn (Source): GitHub. Build: AWS CodeBuild (Chạy unit tests). Deploy: CloudFormation/SAM deploy. Tối ưu chi phí: Thiết lập chính sách vòng đời S3 cho logs và cài đặt cảnh báo ngân sách (AWS Budget) cho dự án. 4. Thành tựu Đến cuối Tuần 12 (và toàn bộ khóa học), các kết quả sau đã đạt được:\n✔ Thành công dự án Hoàn thành và bàn giao một ứng dụng đám mây chuẩn production kết hợp hơn 10 dịch vụ AWS. Chứng minh khả năng tích hợp kho dữ liệu Quan hệ (RDS) và Phi quan hệ (DynamoDB) trong cùng một hệ thống. Đạt được kiến trúc Bảo mật (Cognito/IAM), Tin cậy (Multi-AZ) và Hiệu năng cao (CloudFront/Caching). ✔ Phát triển chuyên môn Làm chủ quy trình xây dựng ứng dụng đám mây từ Phân tích yêu cầu → Thiết kế → Triển khai → Vận hành. Phát triển kỹ năng khắc phục sự cố (troubleshooting) mạnh mẽ cho các hệ thống phân tán phức tạp. Hoàn thành lộ trình học tập và hoàn toàn sẵn sàng cho kỳ thi AWS Certified Solutions Architect – Associate. 5. Thách thức gặp phải \u0026amp; Giải pháp Thách thức 1: Kết nối Lambda trong VPC\nVấn đề: Hàm Lambda trong Private Subnet mất kết nối internet (không thể gọi API công khai hoặc DynamoDB). Giải pháp: Cấu hình NAT Gateway trong Public Subnet và cập nhật Route Tables. Đồng thời sử dụng VPC Endpoint cho DynamoDB để giữ lưu lượng nội bộ và giảm chi phí NAT. Thách thức 2: Lỗi Build trong CodePipeline\nVấn đề: File buildspec.yml thất bại do thiếu thư viện Python phụ thuộc. Giải pháp: Cập nhật pha install trong file buildspec để thực thi lệnh pip install -r requirements.txt. Thách thức 3: CORS với Cognito\nVấn đề: API Gateway từ chối các yêu cầu có token hợp lệ do thiếu header CORS trên phản hồi lỗi 401. Giải pháp: Cấu hình \u0026ldquo;Gateway Responses\u0026rdquo; trong API Gateway để bao gồm header CORS ngay cả đối với các lỗi Unauthorized. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Tùy chỉnh mô hình, RAG, hay cả hai: Nghiên cứu điển hình với Amazon Nova Trong bối cảnh Generative AI phát triển mạnh mẽ, việc lựa chọn chiến lược tối ưu để nâng cao độ chính xác của mô hình ngôn ngữ lớn (LLM) cho các miền dữ liệu cụ thể là một thách thức lớn. Bài viết này thực hiện một nghiên cứu điển hình sử dụng các mô hình Amazon Nova để so sánh hiệu quả giữa ba phương pháp tiếp cận phổ biến: Tinh chỉnh mô hình (Fine-tuning), Thế hệ tăng cường truy xuất (RAG), và phương pháp Kết hợp (Hybrid). Thông qua các thử nghiệm thực tế trên bộ dữ liệu tài liệu AWS, bài viết phân tích sâu về hiệu suất, chi phí và độ phức tạp kỹ thuật, giúp các nhà phát triển và doanh nghiệp đưa ra quyết định sáng suốt nhất cho ứng dụng AI của mình.\nBlog 2 - Di chuyển ứng dụng CDK phiên bản 1 sang CDK phiên bản 2 với Amazon Q Developer Với việc AWS CDK phiên bản 1 chính thức ngừng hỗ trợ, các nhà phát triển đang đối mặt với nhu cầu cấp thiết phải nâng cấp lên phiên bản 2 để đảm bảo tính bảo mật và tận dụng các tính năng mới nhất. Bài viết này hướng dẫn chi tiết cách sử dụng Amazon Q Developer – trợ lý lập trình được hỗ trợ bởi AI – để tự động hóa và tăng tốc quá trình di chuyển này. Từ việc cập nhật các phần phụ thuộc (dependencies), sửa đổi câu lệnh nhập (imports) đến gỡ lỗi và tạo tài liệu, bạn sẽ khám phá cách Amazon Q giúp việc hiện đại hóa cơ sở hạ tầng dưới dạng mã (IaC) trở nên đơn giản, nhanh chóng và ít lỗi hơn.\nBlog 3 - Melting The Ice - Cách Natural Intelligence đơn giản hóa việc chuyển đổi Data lake sang Apache Iceberg Việc di chuyển một Data Lake quy mô lớn đang hoạt động sang định dạng bảng hiện đại như Apache Iceberg thường đi kèm với rủi ro gián đoạn hệ thống và phức tạp về mặt kỹ thuật. Bài viết này là câu chuyện thành công của Natural Intelligence trong việc chuyển đổi từ Apache Hive sang Apache Iceberg mà không có thời gian chết (zero downtime). Các tác giả chia sẻ chi tiết về chiến lược di chuyển \u0026ldquo;lai\u0026rdquo; (hybrid migration strategy) đầy sáng tạo, sử dụng cơ chế đồng bộ hóa thay đổi dữ liệu (CDC) và lược đồ tự động giữa hệ thống cũ và mới. Đây là tài liệu tham khảo quý giá về kiến trúc và quy trình cho các tổ chức muốn hiện đại hóa nền tảng dữ liệu lớn một cách an toàn và hiệu quả.\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/Le-Minh-Tuan-FCJ-AWS-FA25-Hugo/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]